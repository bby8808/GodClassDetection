create record reader
log
setmask
clearmask
greater icost
lesser icost
small thresh
depth thresh
qsort stack size
last
orig ptr
block size 1 0 0k
block randomised
bytes out
bs buff
bs live
m crc
in use
n in use
seq to unseq
unseq to seq
selector
selector mtf
block
quadrant
zptr
szptr
ftab
n m t f
mtf freq
work factor
work done
work limit
first attempt
n blocks randomised
current char
run length
written
closed
empty file array
block c r c
combined c r c
allowable block size
bs stream
incs
panic
make maps
hb make code lengths
c b zip 2 output stream
c b zip 2 output stream
write
write run
finalize
close
flush
initialize
init block
end block
end compression
hb assign codes
bs set stream
bs finished with stream
bs w
bs put u char
bs putint
bs put int v s
send m t f values
move to front code and send
simple sort
vswap
med 3
q sort 3
main sort
randomise block
do reversible transformation
full gt u
allocate compress structures
generate m t f values
crc 3 2 table
global crc
crc
initialise c r c
get final c r c
get global c r c
set global c r c
update c r c
last
orig ptr
block size 1 0 0k
block randomised
bs buff
bs live
m crc
in use
n in use
seq to unseq
unseq to seq
selector
selector mtf
tt
ll 8
unzftab
limit
base
perm
min lens
inner bs stream
read limit
read count
stream end
current char
start block state
rand part a state
rand part b state
rand part c state
no rand part a state
no rand part b state
no rand part c state
current state
stored block c r c
stored combined c r c
computed block c r c
computed combined c r c
check computed combined c r c
i 2
count
ch prev
ch 2
i
t pos
r n to go
r t pos
j 2
z
ret pos
end offset of split
signal to stop reading
mask
eob
eos
cadvise
compressed stream e o f
make maps
get read limit
set read limit
get read count
c b zip 2 input stream
c b zip 2 input stream
read
get pos
initialize
init block
end block
complete
block overrun
bad block header
crc error
bs finished with stream
bs set stream
read bs
bs r
bs get u char
bs getint
bs get int v s
bs get int 3 2
hb create decode tables
recv decoding tables
get and move to front decode
setup block
setup rand part a
setup no rand part a
setup rand part b
setup rand part c
setup no rand part b
setup no rand part c
set decompress structure sizes
log
session
factories
get factory
get factory
s s h socket impl factory
create socket impl
is enabled
log
ssh
static flag
bufpos
bufsize
available
token begin
bufline
bufcolumn
column
line
prev char is c r
prev char is l f
input stream
next char buf
buffer
max next char ind
next char ind
in buf
tab size
hexval
set tab size
get tab size
expand buff
fill buff
read byte
begin token
adjust buff size
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
java char stream
java char stream
java char stream
re init
re init
re init
java char stream
java char stream
java char stream
java char stream
java char stream
java char stream
re init
re init
re init
re init
re init
re init
get image
get suffix
done
adjust begin line column
serial version u i d
lexical error
static lexer error
invalid lexical state
loop detected
error code
add escapes
lexical error
get message
token mgr error
token mgr error
token mgr error
jjtree
pig context
aliases
op table
scope
node id gen
map alias op
log
bracketed
scalar found
file name map
perl
python
single quote
double quote
inside generate
generate inputs
name to type map
token source
jj input stream
token
jj nt
jj ntk
jj scanpos
jj lastpos
jj la
jj looking ahead
jj sem l a
jj gen
jj la 1
jj la 1 0
jj la 1 1
jj la 1 2
jj la 1 3
jj 2 rtns
jj rescan
jj gc
jj ls
jj expentries
jj expentry
jj kind
jj lasttokens
jj endpos
get next id
query parser
query parser
remove quotes
generate store plan
unquote
undollar
get current dir
parse cogroup
parse using for group by
parse join
rewrite join
parse using for join
assert atomic
add split output
add alias
get op
get remote hosts
set hdfs servers
check auto ship specs
check and ship
is quoted string
in skip paths
which
split args
inside generate
set inside generate
get generate inputs
reset generate inputs
add generate input
reset generate state
check generate input
add logical plan
get logical plan
attach plan
is column projections or star
construct file name signature
attach col pos to read scalar
parse
split clause
expr
nested expr
identifier or reserved
alias
base expr
load clause
string list
map reduce clause
file name
filter clause
sample clause
limit clause
p cond
p or cond
p and cond
p unary cond
p not cond
p null cond
cogroup clause
join item
group item
order clause
sort col
col name or num
cross clause
join clause
union clause
for each clause
stream clause
command
define clause
path list
input output spec
command stream
error spec
store clause
nested block
nested command
nested project
nested filter
nested sort or arrange
nested distinct
nested limit
generate statement
flattened generate item list
flattened generate item
infix expr
additive expr
multiplicative expr
cast expr
unary expr
negative expr
base eval spec
bin cond
eval func spec
non eval func spec
eval args
eval args item
type
composite type
basic type
field schema
atom schema
schema map
schema tuple
schema bag
tuple schema
type field schema
type atom schema
type schema map
type schema tuple
type schema bag
type tuple schema
eval class
class name
qualified function
bracketed simple proj
simple proj
bag
tuple
map
key value pair
string datum
atom datum
datum
const
col or spec
dollar var
alias field or spec
jj 2 1
jj 2 2
jj 2 3
jj 2 4
jj 2 5
jj 2 6
jj 2 7
jj 2 8
jj 2 9
jj 2 1 0
jj 2 1 1
jj 2 1 2
jj 2 1 3
jj 2 1 4
jj 2 1 5
jj 2 1 6
jj 2 1 7
jj 2 1 8
jj 2 1 9
jj 2 2 0
jj 2 2 1
jj 2 2 2
jj 2 2 3
jj 2 2 4
jj 2 2 5
jj 2 2 6
jj 2 2 7
jj 2 2 8
jj 2 2 9
jj 2 3 0
jj 2 3 1
jj 2 3 2
jj 2 3 3
jj 2 3 4
jj 2 3 5
jj 2 3 6
jj 3 1 1
jj 3 1 4
jj 3 r 1 4 9
jj 3 r 3 4
jj 3 1 3
jj 3 r 1 0 2
jj 3 r 1 2 2
jj 3 r 1 2 4
jj 3 r 1 0 0
jj 3 r 1 2 1
jj 3 r 1 0 1
jj 3 r 5 9
jj 3 r 4 2
jj 3 r 1 4 5
jj 3 r 1 2 8
jj 3 r 5 4
jj 3 3
jj 3 r 5 3
jj 3 r 3 1
jj 3 r 1 4 8
jj 3 r 1 2 7
jj 3 r 1 2 5
jj 3 r 1 2 6
jj 3 r 1 0 4
jj 3 r 1 0 3
jj 3 r 1 1 2
jj 3 r 1 3 7
jj 3 r 6 0
jj 3 r 8 2
jj 3 r 1 1 1
jj 3 r 4 1
jj 3 r 8 0
jj 3 r 1 7 4
jj 3 6
jj 3 2 3
jj 3 r 6 1
jj 3 r 8 1
jj 3 r 3 6
jj 3 r 4 8
jj 3 r 1 5 7
jj 3 r 4 7
jj 3 r 1 6 3
jj 3 r 1 5 8
jj 3 1 0
jj 3 r 3 5
jj 3 r 4 9
jj 3 1 8
jj 3 r 1 4 3
jj 3 r 1 4 2
jj 3 r 1 4 1
jj 3 r 7 7
jj 3 9
jj 3 2
jj 3 1
jj 3 r 1 4 0
jj 3 r 5 0
jj 3 r 1 6 2
jj 3 3 4
jj 3 r 1 3 3
jj 3 3 3
jj 3 3 2
jj 3 r 7 6
jj 3 3 1
jj 3 1 7
jj 3 r 6 9
jj 3 r 6 8
jj 3 r 6 7
jj 3 r 6 6
jj 3 r 3 8
jj 3 r 1 5 1
jj 3 r 1 5 0
jj 3 r 1 3 2
jj 3 r 5 6
jj 3 r 1 3 6
jj 3 r 1 3 1
jj 3 3 6
jj 3 r 1 3 5
jj 3 r 5 5
jj 3 r 3 2
jj 3 r 7 3
jj 3 3 0
jj 3 r 7 5
jj 3 r 7 2
jj 3 r 1 3 0
jj 3 r 4 0
jj 3 r 1 2 9
jj 3 r 1 0 5
jj 3 2 1
jj 3 r 1 1 0
jj 3 r 1 3 4
jj 3 r 1 0 9
jj 3 r 1 0 8
jj 3 r 8 7
jj 3 2 9
jj 3 r 7 4
jj 3 r 8 6
jj 3 r 1 0 7
jj 3 r 8 5
jj 3 r 8 4
jj 3 r 4 4
jj 3 r 5 1
jj 3 2 2
jj 3 8
jj 3 r 7 1
jj 3 7
jj 3 r 3 9
jj 3 1 6
jj 3 r 7 0
jj 3 r 9 2
jj 3 r 1 3 9
jj 3 r 9 1
jj 3 2 8
jj 3 r 7 8
jj 3 r 9 0
jj 3 r 1 3 8
jj 3 r 9 3
jj 3 r 1 1 7
jj 3 r 4 3
jj 3 r 8 9
jj 3 5
jj 3 r 8 8
jj 3 r 5 2
jj 3 r 1 7 5
jj 3 2 0
jj 3 r 7 9
jj 3 r 1 1 8
jj 3 r 4 5
jj 3 r 1 6 7
jj 3 r 1 6 6
jj 3 r 1 0 6
jj 3 r 1 6 1
jj 3 r 1 5 3
jj 3 r 1 7 8
jj 3 r 1 6 0
jj 3 r 1 5 9
jj 3 r 1 4 4
jj 3 r 9 6
jj 3 1 5
jj 3 r 1 7 7
jj 3 4
jj 3 r 4 6
jj 3 r 1 6 9
jj 3 2 7
jj 3 2 6
jj 3 r 9 7
jj 3 2 5
jj 3 2 4
jj 3 r 1 7 3
jj 3 r 1 6 8
jj 3 r 1 5 4
jj 3 3 5
jj 3 r 1 1 6
jj 3 r 1 1 5
jj 3 r 1 1 4
jj 3 r 5 7
jj 3 r 1 1 3
jj 3 r 9 5
jj 3 1 9
jj 3 r 1 7 9
jj 3 r 1 1 9
jj 3 r 1 7 2
jj 3 r 3 3
jj 3 1 2
jj 3 r 1 5 6
jj 3 r 6 5
jj 3 r 6 4
jj 3 r 9 4
jj 3 r 1 2 0
jj 3 r 6 3
jj 3 r 8 3
jj 3 r 1 7 1
jj 3 r 9 8
jj 3 r 1 7 0
jj 3 r 1 5 5
jj 3 r 1 8 0
jj 3 r 6 2
jj 3 r 1 7 6
jj 3 r 3 7
jj 3 r 9 9
jj 3 r 1 6 5
jj 3 r 1 6 4
jj 3 r 1 5 2
jj 3 r 1 4 7
jj 3 r 1 4 6
jj 3 r 5 8
jj 3 r 1 2 3
jj la 1 init 0
jj la 1 init 1
jj la 1 init 2
jj la 1 init 3
query parser
query parser
re init
re init
query parser
re init
query parser
re init
jj consume token
jj scan token
get next token
get token
jj ntk
jj add error token
generate parse exception
enable tracing
disable tracing
jj rescan token
jj save
nodes
marks
sp
mk
node created
j j t query parser state
node created
reset
root node
push node
pop node
peek node
node arity
clear node scope
open node scope
close node scope
close node scope
serial version u i d
current token
expected token sequences
token image
eol
parse exception
parse exception
parse exception
initialise
add escapes
serial version u i d
kind
begin line
begin column
end line
end column
image
next
special token
get value
token
token
token
to string
new token
new token
parent
children
id
value
parser
simple node
simple node
jjt open
jjt close
jjt set parent
jjt get parent
jjt add child
jjt get child
jjt get num children
jjt set value
jjt get value
to string
to string
dump
debug stream
jjbit vec 0
jjbit vec 2
jjnext states
jjstr literal images
lex state names
jjto token
jjto skip
input stream
jjrounds
jjstate set
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj move string literal dfa 7 0
jj move string literal dfa 8 0
jj move string literal dfa 9 0
jj move string literal dfa 1 0 0
jj move string literal dfa 1 1 0
jj start nfa with states 0
jj move nfa 0
jj can move 0
query parser token manager
query parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
jj check n add
jj add states
jj check n add two states
jj check n add states
serial version u i d
kind
begin line
begin column
end line
end column
image
next
special token
get value
token
token
token
to string
new token
new token
pc
out
token source
jj input stream
token
jj nt
jj ntk
jj scanpos
jj lastpos
jj la
jj gen
jj la 1
jj la 1 0
jj 2 rtns
jj rescan
jj gc
jj ls
jj expentries
jj expentry
jj kind
jj lasttokens
jj endpos
set context
set output writer
unquote
parse
input
param value
others
param string
write ignore toks
ignore toks nonewline
ignore toks
space or newline
write newline
jj 2 1
jj 2 2
jj 2 3
jj 2 4
jj 2 5
jj 2 6
jj 2 7
jj 2 8
jj 2 9
jj 2 1 0
jj 2 1 1
jj 2 1 2
jj 2 1 3
jj 2 1 4
jj 2 1 5
jj 2 1 6
jj 2 1 7
jj 2 1 8
jj 2 1 9
jj 2 2 0
jj 2 2 1
jj 2 2 2
jj 2 2 3
jj 2 2 4
jj 2 2 5
jj 2 2 6
jj 2 2 7
jj 2 2 8
jj 2 2 9
jj 2 3 0
jj 2 3 1
jj 2 3 2
jj 3 1 3
jj 3 r 1 1
jj 3 2 7
jj 3 1 2
jj 3 8
jj 3 r 1 0
jj 3 7
jj 3 r 8
jj 3 2 6
jj 3 6
jj 3 2 5
jj 3 5
jj 3 2 4
jj 3 r 9
jj 3 4
jj 3 3
jj 3 2 3
jj 3 2
jj 3 r 7
jj 3 2 2
jj 3 2 1
jj 3 r 1 3
jj 3 1
jj 3 2 0
jj 3 1 8
jj 3 1 9
jj 3 3 2
jj 3 r 1 4
jj 3 3 1
jj 3 1 0
jj 3 1 7
jj 3 1 6
jj 3 3 0
jj 3 r 1 5
jj 3 r 1 2
jj 3 2 9
jj 3 1 5
jj 3 9
jj 3 1 4
jj 3 1 1
jj 3 2 8
jj la 1 init 0
pig file parser
pig file parser
re init
re init
pig file parser
re init
pig file parser
re init
jj consume token
jj scan token
get next token
get token
jj ntk
jj add error token
generate parse exception
enable tracing
disable tracing
jj rescan token
jj save
static flag
bufpos
bufsize
available
token begin
bufline
bufcolumn
column
line
prev char is c r
prev char is l f
input stream
next char buf
buffer
max next char ind
next char ind
in buf
tab size
hexval
set tab size
get tab size
expand buff
fill buff
read byte
begin token
adjust buff size
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
java char stream
java char stream
java char stream
re init
re init
re init
java char stream
java char stream
java char stream
java char stream
java char stream
java char stream
re init
re init
re init
re init
re init
re init
get image
get suffix
done
adjust begin line column
serial version u i d
current token
expected token sequences
token image
eol
parse exception
parse exception
parse exception
initialise
add escapes
debug stream
jjbit vec 0
jjbit vec 2
jjnext states
jjstr literal images
lex state names
input stream
jjrounds
jjstate set
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj move string literal dfa 7 0
jj move nfa 0
jj can move 0
pig file parser token manager
pig file parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
jj check n add
jj add states
jj check n add two states
jj check n add states
serial version u i d
lexical error
static lexer error
invalid lexical state
loop detected
error code
add escapes
lexical error
get message
token mgr error
token mgr error
token mgr error
pc
token source
jj input stream
token
jj nt
jj ntk
jj gen
jj la 1
jj la 1 0
jj expentries
jj expentry
jj kind
set context
unquote
parse
jj la 1 init 0
param loader
param loader
re init
re init
param loader
re init
param loader
re init
jj consume token
get next token
get token
jj ntk
generate parse exception
enable tracing
disable tracing
debug stream
jjbit vec 0
jjbit vec 2
jjnext states
jjstr literal images
lex state names
jjto token
jjto skip
input stream
jjrounds
jjstate set
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move nfa 0
jj can move 0
param loader token manager
param loader token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
jj check n add
jj add states
jj check n add two states
jj check n add states
m interactive
m console reader
token source
jj input stream
token
jj nt
jj ntk
jj gen
jj la 1
jj la 1 0
jj la 1 1
jj la 1 2
jj la 1 3
jj expentries
jj expentry
jj kind
set interactive
get line number
set console reader
prompt
quit
print aliases
process fs command
process sh command
process describe
process explain
process register
process register
process set
process cat
process c d
process dump
process kill
process l s
process p w d
print help
process move
process copy
process copy to local
process copy from local
process mkdir
process pig
process remove
process illustrate
process script
unquote
parse
explain
script
get path
get key
get value
get reserved
handle invalid command
jj la 1 init 0
jj la 1 init 1
jj la 1 init 2
jj la 1 init 3
pig script parser
pig script parser
re init
re init
pig script parser
re init
pig script parser
re init
jj consume token
get next token
get token
jj ntk
generate parse exception
enable tracing
disable tracing
serial version u i d
kind
begin line
begin column
end line
end column
image
next
special token
get value
token
token
token
to string
new token
new token
serial version u i d
lexical error
static lexer error
invalid lexical state
loop detected
error code
add escapes
lexical error
get message
token mgr error
token mgr error
token mgr error
static flag
bufpos
bufsize
available
token begin
bufline
bufcolumn
column
line
prev char is c r
prev char is l f
input stream
next char buf
buffer
max next char ind
next char ind
in buf
tab size
hexval
set tab size
get tab size
expand buff
fill buff
read byte
begin token
adjust buff size
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
java char stream
java char stream
java char stream
re init
re init
re init
java char stream
java char stream
java char stream
java char stream
java char stream
java char stream
re init
re init
re init
re init
re init
re init
get image
get suffix
done
adjust begin line column
serial version u i d
current token
expected token sequences
token image
eol
parse exception
parse exception
parse exception
initialise
add escapes
pig block level
func block level
tuple schema level
bag schema level
bag constant level
prev state
interactive
console reader
stack
debug stream
jjbit vec 0
jjbit vec 2
jjnext states
jjstr literal images
lex state names
jjnew lex state
jjto token
jjto skip
jjto more
input stream
jjrounds
jjstate set
jjimage
image
jjimage len
length of match
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
secondary prompt
get state
save state
set debug stream
jj stop string literal dfa 1 0
jj start nfa 1 0
jj stop at pos
jj move string literal dfa 0 1 0
jj move string literal dfa 1 1 0
jj move nfa 1 0
jj stop string literal dfa 6
jj start nfa 6
jj move string literal dfa 0 6
jj move nfa 6
jj stop string literal dfa 9
jj start nfa 9
jj move string literal dfa 0 9
jj move string literal dfa 1 9
jj move nfa 9
jj stop string literal dfa 7
jj start nfa 7
jj move string literal dfa 0 7
jj move nfa 7
jj stop string literal dfa 5
jj start nfa 5
jj move string literal dfa 0 5
jj move string literal dfa 1 5
jj move nfa 5
jj stop string literal dfa 0
jj start nfa 0
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj move string literal dfa 7 0
jj move string literal dfa 8 0
jj move string literal dfa 9 0
jj move string literal dfa 1 0 0
jj move string literal dfa 1 1 0
jj move string literal dfa 1 2 0
jj start nfa with states 0
jj move nfa 0
jj stop string literal dfa 4
jj start nfa 4
jj move string literal dfa 0 4
jj move string literal dfa 1 4
jj move nfa 4
jj stop string literal dfa 8
jj start nfa 8
jj move string literal dfa 0 8
jj move nfa 8
jj stop string literal dfa 3
jj start nfa 3
jj move string literal dfa 0 3
jj move string literal dfa 1 3
jj move nfa 3
jj move string literal dfa 0 2
jj move nfa 2
jj move string literal dfa 0 1 1
jj stop string literal dfa 1
jj start nfa 1
jj move string literal dfa 0 1
jj move string literal dfa 1 1
jj move nfa 1
jj can move 0
pig script parser token manager
pig script parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
more lexical actions
token lexical actions
jj check n add
jj add states
jj check n add two states
jj check n add states
log
graphs
curr d a g
pig context
scope counter
scope
aggregate warning
is multi query
parse exec type
construct scope
pig server
pig server
pig server
pig server
pig server
add jars from properties
get pig context
debug on
debug off
set default parallel
set batch on
is batch on
is batch empty
execute batch
execute batch ex
discard batch
add path to skip
register function
register function
register streaming command
locate jar from resources
register jar
register code
register query
get cloned graph
register query
register script
register script
register script
register script
print aliases
dump schema
dump schema nested
set job name
set job priority
open iterator
store
store
store ex
explain
explain
capacity
file size
exists file
delete file
rename file
mkdirs
list paths
total hadoop time spent
get aliases
shutdown
get alias key set
get examples
get store plan
execute
execute compiled logical plan
compile lp
compile lp
merge scalars
compile lp
compile lp
compile pp
validate
get plan from alias
serial version u i d
class name
ctor args
input args schema
func spec
func spec
func spec
func spec
func spec
get class name from spec
get arg string from spec
parse arguments
get class name
set class name
get ctor args
set ctor args
to string
get input args schema
set input args schema
equals
hash code
clone
get split comparable
op type
get op type
log
l o g 4 j c o n f
brief
debug
verbose
main
run
get return code for stats
configure log 4 j
run param preprocessor
get version string
usage
print properties
validate log file
get file from canonical path
serial version u i d
is globally sorted
sort col info list
sort info
get sort col info list
hash code
is globally sorted
equals
to string
rel to abs path for store location
get output format
set store location
check schema
prepare to write
put next
set store func u d f context signature
cleanup on failure
cleanup on failure impl
serial version u i d
input
bug
user environment
remote environment
error
error code
error source
retriable
detailed message
is input
is bug
is user environment
is remote environment
determine error source
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
pig exception
retriable
set retriable
get error source
set error source
get error code
set error code
get detailed message
set detailed message
to string
serial version u i d
m bytes
num records
avg record size
fields
getm bytes
setm bytes
get num records
set num records
get avg record size
set avg record size
get fields
set fields
equals
hash code
to string
clone
reporter
comparison func
compare
compare
set reporter
run
reporter
log
pig logger
next schema id
return type
get schema name
eval func
get return type from spec
get return type
progress
warn
finish
exec
output schema
is asynchronous
get reporter
set reporter
get arg to func mapping
get pig logger
set pig logger
get logger
finish
relative to absolute path
set location
get input format
get load caster
prepare to read
get next
join
get path strings
get absolute path
set u d f context signature
serial version u i d
filename
offset
file split comparable
file split comparable
compare to
read fields
write
to string
hash code
equals
serial version u i d
col name
col index
sort order
sort col info
get col name
get col index
get sort order
hash code
equals
to string
log
pig
main
try parse
serial version u i d
log
fields
sort keys
sort key orders
version
resource schema
resource schema
resource schema
get version
set version
get fields
field names
set fields
get sort keys
set sort keys
get sort key orders
set sort key orders
equals
to string
stringify resource schema
serial version u i d
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
backend exception
seek
tell
serial version u i d
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
data storage exception
destination
immutable output stream
write
serial version u i d
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
exec exception
value
double writable
double writable
read fields
write
set
get
equals
hash code
compare to
to string
bool writ
bytes writ
string writ
float writ
double writ
int writ
long writ
def d b
def tup
type to name
get writable comparable types
get writable comparable types
input
content length
h seekable input stream
seek
tell
read
read
read
available
skip
close
mark
reset
mark supported
serial version u i d
h configuration
h configuration
get configuration
h directory
h directory
h directory
h directory
h directory
h directory
create
copy
open
open
sopen
sopen
iterator
to configuration
to properties
merge conf
get local f s properties
h file
h file
h file
h file
h file
h file
create
open
open
sopen
sopen
path
fs
h path
h path
h path
h path
h path
h path
get data storage
create
copy
open
sopen
exists
rename
delete
get configuration
update configuration
get statistics
create
copy
get path
get h f s
system element
to string
equals
compare to
hash code
file system location
fs
configuration
properties
uri
h data storage
h data storage
init
close
get configuration
update configuration
get statistics
as element
as element
as element
as element
as element
as container
as container
as container
as container
as container
set active container
get active container
is container
as collection
get h f s
out file spec
parallelism request
map red result
log
status
pig context
out file spec
backend exception
alias
po store
stats
h job
h job
get status
has completed
get results
get configuration
get statistics
completion notification
kill
get logs
get s t d out
get s t d error
set exception
get exception
get alias
get p o store
job tracker location
file system location
hadoop site
core site
log
local
pig context
ds
job conf
logical to physical keys
materialized results
h execution engine
get job conf
get materialized results
get data storage
init
init
get configuration
update configuration
close
get statistics
compile
execute
explain
set s s h factory
recompute properties
check leaf is store
serial version u i d
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
m r compiler exception
instance
log
reporter
aggregate
get instance
pig hadoop logger
warn
set reporter
get aggregate
set aggregate
mapred output dir
mapred task partition
pig mapred output dir
pig tmp path
reduce stores
map stores
current conf
get record writer
set location
check output specs
check output specs helper
get stores
setup udf env and stores
is conf prop equal
get output committer
m log
m asc
m wrapped comp
pig bytes raw comparator
set conf
get conf
compare
compare
m log
m asc
m wrapped comp
pig float raw comparator
set conf
get conf
compare
compare
context
reporter
writer
map reduce p o store impl
create store func
tear down
clean up
create record counter
serial version u i d
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
job creation exception
m log
m asc
m whole tuple
m fact
m has null field
pig tuple default raw comparator
set conf
get conf
has compared tuple null
compare
compare
compare tuple
list status
m log
m asc
m wrapped comp
pig long raw comparator
set conf
get conf
compare
compare
s job context
m log
m comparator
set conf
pig secondary key comparator
get conf
compare
log
accumulator optimizer
visit m r op
check
check u d f input
log
job control exception
job control exception stack trace
aggregate warning
failure map
succeeded file name
successful job output dir marker
get error
reset
launch pig
get stack strace str
notify progress
explain
compile
store schema
should mark output dir
create success file
compute warning aggregate
log
nig
scope
multi query optimizer
visit
visit m r op
is diamond m r oper
merge diamond m r oper
merge one map part
merge only mapper splittee
merge only map reduce splittee
merge all map only splittees
is splittee mergeable
get merge list
merge map reduce splittees
merge map reduce splittees
has same map key type
set index on l r in split
merge one map plan with index
merge one reduce plan with index
add shifted key info index
add shifted key info index
merge one combine plan with index
need combiner
create demux plan
merge all map reduce splittees
merge single map reduce splittee
remove and reconnect
merge m r oper properties
is map only
is single load mapper plan
is single predecessor
get split
get m r oper
get store
get demux
get multi query package
log
num m r use secondary key
num distinct changed
num sort removed
secondary key optimizer
get sort key info
visit m r op
set secondary plan
get num m r use secondary key
get num sort removed
get distinct changed
collect column chain
serial version u i d
count jobs
native m r jar
params
native map reduce oper
get job number
get job id
get command string
get native m r params
visit
run job
name
dummytuple
log
key type
mp
stores
tf
output collector
pig reporter
error in map
roots
leaf
pig context
initialized
cleanup
setup
map
run pipeline
collect
get key type
set key type
serial version u i d
map plan
reduce plan
combine plan
map key type
map done
reduce done
end of all input in map
end of all input in reduce
global sort
limit after sort
limit only
feature
needs distinct combiner
use secondary key
quant file
sort order
secondary sort order
u d fs
scalars
is u d f comparator used
nig
scope
requested parallelism
custom partitioner
limit
splitter
skewed join
skewed join partition file
using typed comparator
combine small splits
map reduce oper
shift string by tabs
name
get u d fs as str
supports multiple inputs
supports multiple outputs
visit
is map done
set map done
set map done single
set map done multiple
get union
is reduce done
set reduce done
is global sort
is skewed join
set skewed join partition file
get skewed join partition file
set skewed join
get skewed join
set global sort
is limit after sort
set limit after sort
is limit only
set limit only
is indexer
mark indexer
is sampler
mark sampler
is group by
mark group by
is cogroup
mark cogroup
is regular join
mark regular join
needs distinct combiner
set needs distinct combiner
get quant file
set quant file
set sort order
set secondary sort order
get sort order
get secondary sort order
is end of all input set in map
set end of all input in map
is end of all input set in reduce
set end of all input in reduce
get requested parallelism
get custom partitioner
set splitter
is splitter
get use secondary key
set use secondary key
using typed comparator
use typed comparator
no combine small splits
combine small splits
log
pig context
ops to remove
sample optimizer
visit
visit m r op
scan
log
replacement map
removal q
store q
noop store remover
visit m r op
remove store
s job context
s job conf
dummytuple
field del
pig text output format
get record writer
target ops
input index
wrapped splits
split index
is multi inputs
conf
total splits
length
locations
pig split
pig split
get target ops
get wrapped split
get wrapped split
get locations
get length
get length
read fields
write
write object
read object
get split index
set multi inputs
is multi inputs
get conf
set conf
get input index
get num paths
get total splits
set total splits
to string
column infos
equals
insert
insert in reduce
insert column chain info
get column infos
to string
clone
size
get column info
hash code
key type discovery visitor
visit m r op
map output committers
reduce output committers
pig output committer
get committers
set up context
set up context
store cleanup
cleanup job
abort task
commit task
needs task commit
setup job
setup task
log
hidden file filter
pig inputs
s job
active split
create record reader
merge split specific conf
get load func
get load location
pass load signature
get splits
get pig splits
create pig split
get active split
log
cur value
cur reader
loadfunc
input record counter
counter name
inputformat
pig split
idx
progress
context
input specific conf
pig record reader
close
get current key
get current value
get progress
initialize
next key value
get multi inputs couner name
init next record reader
m log
m asc
m whole tuple
m comparator
pig tuple sort comparator
set conf
get conf
compare
compare
compare tuple
exit invoked
exit code
security manager
internal
run jar security manager
check permission
retire
check exit
get exit invoked
get exit code
parent
phy plan setter
visit load
visit native
visit store
visit filter
visit local rearrange
visit collected group
visit global rearrange
visit package
visit combiner package
visit p o for each
visit union
visit split
visit demux
visit distinct
visit read
visit sort
visit constant
visit project
visit greater than
visit less than
visit g t or equal
visit l t or equal
visit equal to
visit not equal to
visit regexp
visit is null
visit add
visit subtract
visit multiply
visit divide
visit mod
visit and
visit or
visit not
visit bin cond
visit negative
visit user func
visit comparison func
visit map look up
visit join package
visit cast
visit limit
visit f r join
visit merge join
visit skewed join
visit stream
visit local rearrange for illustrate
visit p o optimized for each
visit pre combiner local rearrange
visit merge co group
plan
conf
pig context
log
log dir
end of inp in map
pig map stores
pig reduce stores
job store map
job mro map
job control compiler
get stores
reset
get job mro map
move results
move results
remove part
compile
update m r op plan
get job
estimate number of reducers
get total input file size
get path length
select comparator
setup distributed cache for join
setup distributed cache
setup distributed cache
add single file to distributed cache
m log
m asc
pig int raw comparator
set conf
get conf
compare
compare
log
total hadoop time spent
new line
pig exception
out of memory
oom err
launcher
reset
launch pig
explain
is complete
get stats
compute time spent
get error messages
calculate progress
progress of running job
get total hadoop time spent
get exception from string
get exception from strings
get stack trace element
get first line from message
m log
m asc
m wrapped comp
pig text raw comparator
set conf
get conf
compare
compare
hidden file filter
list status
columns
star
result type
column info
to string
equals
hash code
first rec
m tuple factory
lr
preceding phy plan
keys cnt
right pipeline leaf
right pipeline root
dummy tuple
loader
pig split
ignore null keys
merge join indexer
get next
get input format
get load caster
prepare to read
set location
u d f finish visitor
visit user func
distinct udf classname
log
m key field
key field positions
m key type
message collector
combiner optimizer
combiner optimizer
get message collector
visit m r op
patch up map
get pre combiner l r
algebraic
algebraic
fix up foreachs
fix project and inputs
set project input
get distinct user func
add key project
change func
fix up rearrange
reset state
m log
m asc
m wrapped comp
pig double raw comparator
set conf
get conf
compare
compare
rep
progressable reporter
progressable reporter
progress
progress
set rep
list status
log
noop filter remover
visit m r op
column chains
ascs
more specific than
insert column chain info
to string
get column chains
get ascs
pig context
plan
m r plan
cur m r op
compiled inputs
splits seen
nig
scope
r
udf finder
message collector
phy to m r op map
user comparator marker
log
file concatenation threshold
optimistic file concatenation
file concatenation threshold
optimistic file concatenation
m r compiler
m r compiler
aggregate scalars files
randomize file localizer
get m r plan
get plan
get message collector
compile
connect soft link
compile
get m r op
get native m r op
get load
get store
non blocking
blocking
conn red oper
end single input plan with str
start new
get temp file spec
merge
merge
process u d fs
visit split
visit load
visit native
visit store
visit filter
visit stream
connect map to reduce limited sort
simple connect map to reduce
get plain for each o p
visit limit
visit local rearrange
visit collected group
visit p o for each
visit global rearrange
visit package
visit union
visit f r join
has too many input files
get concatenate job
visit merge co group
get indexing job
visit merge join
visit distinct
visit skewed join
visit sort
get sort cols
get sort job
get quantile job
get skewed join sample job
get sampling job
quantiles
comparator
weighted parts
log
job
get partition
set conf
get prob vec
get pig nullable writable
convert to array
get list
get conf
r gen
prob vec
epsilon
log
discrete probability sample generator
get next
main
to string
reducer map
current index map
total reducers
conf
get partition
set conf
get conf
kt
get partition
get conf
set conf
serial version u i d
total count
put
display
get total count
scalars
scalar phy finder
get scalars
visit user func
serial version u i d
m r oper plan
to string
m stream
is verbose
m r printer
set verbose
visit m r op
p o package annotator
visit m r op
handle package
patch package
end of all input setter
visit m r op
counter
is verbose nesting
dot m r printer
dot m r printer
set verbose
make dumper
get name
get nested plans
get attributes
m r op plan visitor
visit m r op
u d fs
dfw
u d f finder
u d f finder
get u d fs
set plan
visit sort
visit user func
visit comparison func
visit cast
status ok
status null
status err
status eop
status eos
status batch ok
result
log
serial version u i d
requested parallelism
inputs
outputs
result type
parent plan
input attached
input
res
alias
reporter
pig logger
dummy d b a
dummy string
dummy double
dummy float
dummy int
dummy long
dummy bool
dummy tuple
dummy bag
dummy map
lineage tracer
accum
accum start
physical operator
physical operator
physical operator
physical operator
set lineage tracer
get requested parallelism
set requested parallelism
get result type
get alias
get alias string
set alias
set accumulative
is accumulative
set accum start
is accum started
set accum end
set result type
get inputs
set inputs
is input attached
attach input
detach input
is blocking
process input
visit
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
reset
set reporter
clone
clone helper
set parent plan
get logger
set pig logger
get pig logger
serial version u i d
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
logical to physical translator exception
log to phy map
current plans
current plan
node gen
pc
log to phy translation visitor
set pig context
get physical plan
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
validate merge cogrp
compile to merge cogrp
compile to l r g r pack trio
translate collected cogroup
visit
compile f e 4 flattening
update with empty bag check
validate map side merge
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
translate soft links
serial version u i d
return status
result
result
result
to string
p o printer
serial version u i d
subtract
subtract
visit
name
get next
get next
get next
get next
clone
serial version u i d
p o or
p o or
visit
name
get next
clone
serial version u i d
multiply
multiply
visit
name
get next
get next
get next
get next
clone
serial version u i d
lhs
rhs
child
binary expression operator
binary expression operator
get lhs
get child expressions
supports multiple inputs
set lhs
get rhs
set rhs
clone helper
serial version u i d
value
res
constant expression
constant expression
name
supports multiple inputs
supports multiple outputs
visit
get value
set value
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
clone
get child expressions
serial version u i d
mod
mod
visit
name
get next
get next
clone
operand type
true ref
false ref
binary comparison operator
binary comparison operator
get operand type
set operand type
initialize refs
clone helper
serial version u i d
p o is null
p o is null
p o is null
visit
name
get next
clone
serial version u i d
log
greater than expr
greater than expr
name
visit
get next
do comparison
clone
serial version u i d
impl
p o regexp
p o regexp
set implementation
visit
name
set const expr
get next
clone
serial version u i d
log
less than expr
less than expr
name
visit
get next
do comparison
clone
serial version u i d
divide
divide
visit
name
get next
get next
get next
get next
clone
serial version u i d
p o negative
p o negative
p o negative
visit
name
get next
get next
get next
get next
clone
serial version u i d
log
equal to expr
equal to expr
name
visit
get next
do comparison
clone
serial version u i d
true res
false res
p o not
p o not
visit
name
get next
clone
func spec
caster
log
cast not needed
real type
child
field schema
serial version u i d
p o cast
p o cast
instantiate func
set func spec
visit
name
supports multiple inputs
get next
get next
get next
get next
get next
get next
get next
get next
read object
clone
get child expressions
set field schema
get func spec
serial version u i d
add
add
visit
name
get next
get next
get next
get next
clone
serial version u i d
log
l t or equal to expr
l t or equal to expr
name
visit
get next
do comparison
clone
serial version u i d
log
g t or equal to expr
g t or equal to expr
name
visit
get next
do comparison
clone
serial version u i d
p o and
p o and
visit
name
get next
clone
serial version u i d
cond
lhs
rhs
child
p o bin cond
p o bin cond
p o bin cond
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
visit
name
attach input
set cond
set rhs
set lhs
get cond
get rhs
get lhs
supports multiple inputs
clone
get child expressions
serial version u i d
func
log
func spec
orig f spec
initial
intermediate
final
initialized
executor
referenced operator
get referenced operator
set referenced operator
p o user func
p o user func
p o user func
instantiate func
process input
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
set algebraic function
get initial
get intermed
get final
get return type
finish
output schema
is asynchronous
name
supports multiple inputs
supports multiple outputs
visit
get func spec
combinable
clone
read object
get child expressions
set accum start
set result type
serial version u i d
log
expression operator
expression operator
supports multiple outputs
get next
visit
clone
get child expressions
contain u d f
accum child
accum child
accum child
accum child
accum child
accum child
accum child
accum child
accum child
accum child
serial version u i d
tuple factory
bag factory
result single tuple bag
columns
processing bag of tuples
bag iterator
overloaded
star
p o project
p o project
p o project
p o project
name
supports multiple inputs
supports multiple outputs
visit
attach input
get next
get next
consume input bag
get next
get next
get next
get next
get next
get next
get next
get next
get next
get columns
get column
set columns
set column
is overloaded
set overloaded
is star
set star
clone
process input bag
set result single tuple bag
get child expressions
expr
child
unary expression operator
unary expression operator
supports multiple inputs
set input as expr
set expr
get expr
clone helper
get child expressions
operand type
unary comparison operator
unary comparison operator
get operand type
set operand type
serial version u i d
log
not equal to expr
not equal to expr
name
visit
get next
do comparison
clone
serial version u i d
key
p o map look up
p o map look up
p o map look up
set look up key
get look up key
visit
name
supports multiple inputs
process input
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
clone
get child expressions
serial version u i d
func spec
t 1
t 2
func
log
p o user comparison func
p o user comparison func
instantiate func
get comparator
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
get next
attach input
read object
visit
name
supports multiple inputs
get func spec
clone
get child expressions
serial version u i d
send empty bag on e o p
p o relation to expr project
p o relation to expr project
p o relation to expr project
p o relation to expr project
name
visit
reset
get next
clone
m
compiled regex
match
serial version u i d
java regex only
regexop
side
rhs constant
regex init
set const expr
determine best regex method
preceding escapes
compile
match
runauto
compiled automaton
match
pattern
old string
matcher
match
serial version u i d
end of all input
physical plan
attach input
detach input
explain
explain
explain
connect
remove
replace
is empty
to string
clone
phy plan visitor
visit load
visit store
visit native
visit filter
visit collected group
visit local rearrange
visit global rearrange
visit package
visit combiner package
visit multi query package
visit p o for each
visit union
visit split
visit demux
visit distinct
visit pen cross
visit pen cogroup
visit pen split
visit read
visit sort
visit constant
visit project
visit greater than
visit less than
visit g t or equal
visit l t or equal
visit equal to
visit not equal to
visit regexp
visit is null
visit add
visit subtract
visit multiply
visit divide
visit mod
visit and
visit or
visit not
visit bin cond
visit negative
visit user func
visit comparison func
visit map look up
visit join package
visit cast
visit limit
visit f r join
visit merge join
visit merge co group
visit stream
visit skewed join
visit partition rearrange
visit local rearrange for illustrate
visit p o optimized for each
visit pre combiner local rearrange
t a b 1
t a b more
l sep
u sep
level cntr
stream
is verbose
plan printer
plan printer
set verbose
visit
print
breadth first
breadth first
depth first p p
plan string
plan string
depth first
shift string by tabs
disp tabs
visit load
visit store
visit filter
visit local rearrange
visit global rearrange
visit package
visit start map
dot p o printer
dot p o printer
make dumper
get name
get attributes
get multi output nested plans
get nested plans
serial version u i d
sort plans
expr output types
m asc cols
m sort func
log
m comparator
inputs accumulated
limit
is u d f comparator used
sorted bag
it
sort info
p o sort
p o sort
p o sort
p o sort
p o sort
name
is blocking
get next
supports multiple inputs
supports multiple outputs
visit
reset
get sort plans
set sort plans
get m sort func
set m sort func
get m asc cols
set limit
get limit
is limited
clone
set sort info
get sort info
serial version u i d
m tuple factory
log
err result
plans
secondary plans
leaf ops
secondary leaf ops
index
key type
main key type
secondary key type
m is distinct
is cross
m projected cols map
m secondary projected cols map
m fake tuple
m project star
m secondary project star
is key tuple
is secondary key tuple
m projected cols map size
m secondary projected cols map size
use secondary key
strip key from value
p o local rearrange
p o local rearrange
p o local rearrange
p o local rearrange
visit
name
supports multiple inputs
supports multiple outputs
get index
set index
set multi query index
set index
is distinct
set distinct
attach input
get next
detach plans
get key from result
construct l r output
get key type
set key type
get plans
set use secondary key
set plans
set secondary plans
clone
is cross
set cross
get projected cols map
get secondary projected cols map
is project star
is secondary project star
is key tuple
is secondary key tuple
set plans from combiner
set strip key from value
serial version u i d
total reducers
reducer map
loaded
m bag factory
pig context
p o partition rearrange
p o partition rearrange
p o partition rearrange
p o partition rearrange
load partition file
name
get next
construct p r output
set pig context
get pig context
clone
serial version u i d
done
next return e o p
eop result
last ind
p o union
p o union
p o union
p o union
set inputs
visit
name
supports multiple inputs
supports multiple outputs
clear done
get next
serial version u i d
side loaders
sid func specs
side file specs
l rs
first time
first key of next split
relation cnt
m tuple factory
index file name
idx func spec
out bags
prev top of heap
loader signatures
create new bags
heap
last time
working on new key
counter
p o merge cogroup
get next
get output tuple
need to break
setup
read index
get first key of next split
apply l ron
visit
name
supports multiple inputs
supports multiple outputs
get l r inner plans of
set side load funcs
set side file specs
get index file name
set index file name
get idx func spec
set idx func spec
set loader signatures
read object
print heap
serial version u i d
log
so far
m limit
p o limit
p o limit
p o limit
p o limit
set limit
get limit
get next
name
supports multiple inputs
supports multiple outputs
visit
reset
clone
serial version u i d
plan
com op
comp operand type
p o filter
p o filter
p o filter
p o filter
get next
name
supports multiple inputs
supports multiple outputs
visit
set plan
get plan
serial version u i d
simple key position
tup iter
key
is key tuple
key as tuple
key type
num inputs
use secondary key
inner
distinct
key info
log
m bag factory
m tuple factory
first time
use default bag
pkg type
p o package
p o package
p o package
p o package
name
supports multiple inputs
visit
supports multiple outputs
attach input
detach input
get num inps
set num inps
get inner
set inner
get next
get value tuple
get key type
set key type
get key positions in tuple
clone
set key info
set key tuple
get key info
is distinct
set distinct
set use secondary key
set package type
get package type
serial version u i d
empty
storer
impl
s file
schema
output record counter
is tmp store
is multi store
l file
sort info
signature
p o store
p o store
p o store
set up
tear down
clean up
get next
name
supports multiple inputs
supports multiple outputs
visit
get s file
set s file
set input spec
get input spec
set is tmp store
is tmp store
set store impl
set schema
get schema
get store func
set sort info
get sort info
get signature
set signature
set multi store
is multi store
serial version u i d
native m rjar
params
p o native
visit
name
get native m rjar
set native m rjar
get params
set params
supports multiple inputs
supports multiple outputs
serial version u i d
m inner flags
input schema
log
m join plans
p o skewed join
p o skewed join
p o skewed join
p o skewed join
get inner flags
get join plans
set join plans
visit
name
supports multiple inputs
supports multiple outputs
add schema
get schema
serial version u i d
idx part
log
packages
is key wrapped
same map key type
in combiner
my key
p o multi query package
p o multi query package
p o multi query package
p o multi query package
name
supports multiple inputs
visit
supports multiple outputs
attach input
detach input
add package
add package
get packages
get next
get is key wrapped list
add is key wrapped list
set in combiner
is in combiner
set same map key type
is same map key type
serial version u i d
log
first time
l rs
right loader
op key
prev left key
prev left inp
prev right key
prev right inp
m tuple factory
doing join
right loader func spec
right input file name
index file
left tuples
inp plans
right pipeline leaf
right pipeline root
no inner plan on right side
cur join key
cur joining right tup
counter
left tup size
right tup size
array list size
signature
p o merge join
create join plans
get next
seek in right stream
get next right inp
throw processing exception
extract keys from tuple
setup right pipeline
read object
gen key
set right loader func spec
get inner plans of
visit
name
supports multiple inputs
supports multiple outputs
set right input file name
get signature
set signature
set index file
get index file
serial version u i d
p o optimized for each
p o optimized for each
p o optimized for each
p o optimized for each
p o optimized for each
visit
name
get next
clone
serial version u i d
log
split store
my plans
processed set
empty
inp e o p
p o split
p o split
p o split
p o split
visit
name
supports multiple inputs
supports multiple outputs
get split store
set split store
get plans
add plan
remove plan
get next
process plan
run pipeline
get stream close result
serial version u i d
p o local rearrange for illustrate
p o local rearrange for illustrate
p o local rearrange for illustrate
p o local rearrange for illustrate
visit
name
construct l r output
clone
empty plan list
serial version u i d
m tuple factory
plans
leaf ops
key type
output
output bag
prev key
use default bag
p o collected group
p o collected group
p o collected group
p o collected group
visit
name
supports multiple inputs
supports multiple outputs
attach input
get next
construct output
get key type
set key type
get plans
set plans
serial version u i d
eop result
executable manager str
executable manager
command
properties
initialized
binary output queue
binary input queue
all input from predecessor consumed
all output from binary processed
p o stream
parse ship cache specs
get ship cache properties
get command
get next
get next helper
to string
visit
name
supports multiple inputs
supports multiple outputs
finish
get binary input queue
get binary output queue
serial version u i d
last tuple
p o sorted distinct
p o sorted distinct
p o sorted distinct
p o sorted distinct
get next
name
serial version u i d
log
m bag factory
m tuple factory
m bags
key positions
key lookup
num bags
p o combiner package
name
visit
set key info
create data bag
get next
get key positions in tuple
serial version u i d
loader
l file
pc
set up done
signature
log
p o load
p o load
p o load
p o load
set up
tear down
get next
name
supports multiple inputs
supports multiple outputs
visit
get l file
set l file
get pc
set pc
get signature
set signature
get load func
create store func
tear down
clean up
serial version u i d
for each
new key
res
last input tuple
t 1
eop result
first time
use default bag
default chunk size
chunk size
for each result
dbs
last bag index
p o join package
visit
name
get next
get input plans
set input plans
set to be flattened
get for each
set chunk size
serial version u i d
log
fragment
phy plan lists
key types
l rs
repl files
const exps
fe
replicates
processing plan
dum tup
m tuple factory
set up
is left outer join
null bag
p o f r join
get join plans
gen key
create join plans
visit
name
supports multiple inputs
supports multiple outputs
get next
set up hash map
is key null
read object
get value tuple
get fragment
set fragment
get repl files
set repl files
serial version u i d
m tuple factory
m bag factory
log
err result
plans
leaf ops
key type
p o pre combiner local rearrange
p o pre combiner local rearrange
p o pre combiner local rearrange
p o pre combiner local rearrange
visit
name
supports multiple inputs
supports multiple outputs
attach input
get next
construct l r output
get key type
set key type
get plans
set plans
serial version u i d
bag
it
p o read
p o read
p o read
p o read
p o read
get next
name
supports multiple inputs
supports multiple outputs
visit
serial version u i d
idx part
empty
eop
log
my plans
get next
inp e o p
cur leaf
cur plan
in combiner
processed set
p o demux
p o demux
p o demux
p o demux
visit
name
supports multiple inputs
supports multiple outputs
get plans
add plan
get next
run pipeline
get stream close result
attach input with index
set in combiner
is in combiner
serial version u i d
input plans
ops to be reset
log
m tuple factory
processing plan
its
bags
data
result types
is to be flattened array
t in
no items
plan leaf ops
buffer
p o for each
p o for each
p o for each
p o for each
p o for each
visit
name
get flat str
supports multiple inputs
supports multiple outputs
set accumulative
set accum start
set accum end
get next
process plan
create tuple
attach input to plans
get leaves
re initialize
get input plans
set input plans
add input plan
set to be flattened
get to be flattened
clone
in processing
set up flattens
get ops to be reset
set ops to be reset
serial version u i d
custom partitioner
get custom partitioner
set custom partitioner
p o global rearrange
p o global rearrange
p o global rearrange
p o global rearrange
visit
name
supports multiple inputs
supports multiple outputs
is blocking
get next
serial version u i d
inputs accumulated
distinct bag
log
it
p o distinct
p o distinct
p o distinct
p o distinct
is blocking
get next
name
supports multiple inputs
supports multiple outputs
reset
visit
clone
serial version u i d
p o package lite
p o package lite
p o package lite
p o package lite
set num inps
get inner
set inner
clone
is distinct
set distinct
get key tuple
get key as tuple
get tup iter
get key
get next
get value tuple
name
log
plan helper
get stores
get loads
get native m rs
make store tmp path
exec
time unit
duration
default value
eval func
closure
error callback
error handler
timeout handler
monitored u d f executor
get default value
terminate
monitor exec
log
file system name
hidden file filter
node comparator
load partition file from local cache
setup u d f context
check leaf is store
get all file recursively
add input path recursively
get combine pig splits
remove splits
input split to string
log
string caster
byte caster
caster property
column list 
m table
m conf
reader
writer
scan
configured options 
valid options 
parser 
load row key 
limit 
caching 
gt 
gte 
lt 
lte 
caster 
schema 
populate valid options
h base storage
h base storage
init scan
add filter
get next
get input format
prepare to read
set location
relative to absolute path
convert scan to string
get load caster
get output format
check schema
prepare to write
put next
obj to bytes
rel to abs path for store location
set store func u d f context signature
set store location
cleanup on failure
get features
push projection
log
gt 
gte 
lt 
lte 
h base table input format
h base table input format
get splits
skip region
bytes to char array
bytes to double
bytes to float
bytes to integer
bytes to long
bytes to map
bytes to tuple
bytes to bag
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
number format
job
script output dir
script log dir
task id
error stream
get output name
hadoop executable manager
configure
exec
close
write error to h d f s
process error
write debug header
write debug footer
compute
intermediate max
exec
get initial
get intermed
get final
max
output schema
accumulate
cleanup
get value
m tuple factory
intermediate sum
intermediate count
exec
get initial
get intermed
get final
combine
count
sum
output schema
accumulate
cleanup
get value
tuple factory
exec
exec
output schema
log
double array class
int array class
float array class
string array class
long array class
array classes
method 
param classes 
is static 
self class 
return type 
invoker
invoker
get return type
drop first class
drop first object
string to class
un primitivize
convert to expected arg
bag to number list
tuple to args
invoke
m tuple factory
m bag factory
exec
output schema
get arg to func mapping
bag factory
tuple factory
exec
get final
get initial
get intermed
create data bag
get distinct from nested bags
get distinct
m tuple factory
intermediate sum
intermediate count
exec
get initial
get intermed
get final
combine
count
sum
output schema
accumulate
cleanup
get value
compute
intermediate max
exec
get initial
get intermed
get final
max
output schema
accumulate
cleanup
get value
exec
output schema
m expression
m pattern
output schema
exec
get arg to func mapping
exec
output schema
get arg to func mapping
m tuple factory
intermediate count
exec
get initial
get intermed
get final
sum
output schema
accumulate
cleanup
get value
log
m bag factory
m tuple factory
randomizer
exec
update top
get arg to func mapping
output schema
get initial
get intermed
get final
compute
exec
output schema
intermediate max
exec
get initial
get intermed
get final
max
output schema
accumulate
cleanup
get value
exec
output schema
compute
compute
compute
exec
output schema
get arg to func mapping
compute
m tuple factory
intermediate sum
intermediate count
exec
get initial
get intermed
get final
combine
count
sum
output schema
get arg to func mapping
accumulate
cleanup
get value
exec
output schema
exec
output schema
get arg to func mapping
schema name
flag
cor
cor
exec
to string
get initial
get intermed
get final
combine
compute all
output schema
compute
exec
output schema
in
m tuple factory
load location
get next
bytes to integer
bytes to long
bytes to float
bytes to double
bytes to char array
bytes to map
bytes to tuple
bytes to bag
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
get input format
get load caster
prepare to read
set location
exec
output schema
get arg to func mapping
invoke for double
invoke for double
invoke for double
invoke for double
m tuple factory
m bag factory
exec
compute diff
intermediate min
exec
get initial
get intermed
get final
min
output schema
accumulate
cleanup
get value
exec
output schema
compute
exec
output schema
invoke for float
invoke for float
invoke for float
invoke for float
exec
output schema
null equals
invoke for int
invoke for int
invoke for int
invoke for int
log
exec
output schema
get arg to func mapping
compute
i
m log
end
rec reader
rec writer
bin storage
get next
put next
bytes to bag
bytes to char array
bytes to double
bytes to float
bytes to integer
bytes to long
bytes to map
bytes to tuple
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
get input format
hash code
get load caster
prepare to read
set location
get output format
prepare to write
set store location
check schema
rel to abs path for store location
get partition keys
get schema
get statistics
set partition filter
set store func u d f context signature
cleanup on failure
log
exec
output schema
compute
exec
get arg to func mapping
m tuple factory
intermediate count
exec
get initial
get intermed
get final
sum
output schema
accumulate
cleanup
get value
invoke for string
invoke for string
invoke for string
invoke for string
in
writer
m log
signature
field del
m proto tuple
m tuple factory
load location
m required columns
m required columns initialized
pig storage
pig storage
get next
put next
read field
push projection
equals
equals
get input format
prepare to read
set location
get output format
prepare to write
set store location
check schema
rel to abs path for store location
hash code
set u d f context signature
get features
set store func u d f context signature
cleanup on failure
exec
output schema
get arg to func mapping
invoke for long
invoke for long
invoke for long
invoke for long
intermediate min
exec
get initial
get intermed
get final
min
output schema
accumulate
cleanup
get value
intermediate min
exec
get initial
get intermed
get final
min
output schema
accumulate
cleanup
get value
exec
exec
output schema
get arg to func mapping
intermediate min
exec
get initial
get intermed
get final
min
output schema
accumulate
cleanup
get value
tuple factory
m expression
m pattern
exec
output schema
get arg to func mapping
compute
record del
field del
out
pig streaming
pig streaming
serialize
deserialize
get load caster
exec
output schema
exec
output schema
schema name
flag
cov
cov
exec
to string
get initial
get intermed
get final
combine
compute all
output schema
intermediate min
exec
get initial
get intermed
get final
min
min doubles
output schema
get arg to func mapping
accumulate
cleanup
get value
output schema
intermediate sum
exec
get initial
get intermed
get final
sum
sum doubles
output schema
get arg to func mapping
accumulate
cleanup
get value
compute
exec
output schema
m bag factory
m tuple factory
m log
m max int
m min int
m max long
m min long
buffer size
utf 8 storage converter
find start char
consume bag
consume tuple
consume map
consume complex type
parse simple type
bytes to bag
bytes to char array
bytes to double
bytes to float
bytes to boolean
bytes to integer
bytes to long
bytes to map
bytes to tuple
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
to bytes
intermediate min
exec
get initial
get intermed
get final
min
output schema
accumulate
cleanup
get value
exec
output schema
compute
intermediate sum
exec
get initial
get intermed
get final
sum
output schema
accumulate
cleanup
get value
exec
output schema
get arg to func mapping
exec
output schema
intermediate sum
exec
get initial
get intermed
get final
sum
output schema
accumulate
cleanup
get value
m tuple factory
intermediate sum
intermediate count
exec
get initial
get intermed
get final
combine
count
sum
output schema
accumulate
cleanup
get value
compute
exec
output schema
get arg to func mapping
exec
output schema
intermediate sum
exec
get initial
get intermed
get final
sum longs
sum
output schema
accumulate
cleanup
get value
intermediate max
exec
get initial
get intermed
get final
max
output schema
accumulate
cleanup
get value
invoker 
generic invoker
generic invoker
generic invoker
generic invoker
exec
output schema
intermediate max
exec
get initial
get intermed
get final
max
max doubles
output schema
get arg to func mapping
accumulate
cleanup
get value
exec
output schema
intermediate sum
exec
get initial
get intermed
get final
sum doubles
sum
output schema
accumulate
cleanup
get value
m tuple factory
intermediate sum
intermediate count
exec
get initial
get intermed
get final
combine
count
sum
output schema
accumulate
cleanup
get value
compute
intermediate max
exec
get initial
get intermed
get final
max
output schema
accumulate
cleanup
get value
exec
output schema
exec
output schema
compute
exec
output schema
get arg to func mapping
interface audience
new tuple
new tuple
new tuple
new tuple no copy
new tuple
tuple class
tuple raw comparator class
unknown
null
boolean
byte
integer
long
float
double
bytearray
chararray
bigchararray
map
tuple
bag
generic writablecomparable
internalmap
error
find type
find type
extract type from class
num types
gen all types
gen all type names
gen type to name map
gen name to type map
find type name
find type name
is complex
is complex
is atomic
is atomic
is schema type
is schema type
compare
compare
to bytes
to bytes
to integer
to integer
to long
to long
to float
to float
to double
to double
to string
to string
to map
to tuple
to bag
spill tuple contents
is number type
is usable type
merge type
map to string
equal byte arrays
determine field schema
determine field schema
determine field schema
log
pig logger
sedes
m contents
m spill files
m size
m last contents size
m mem size
start bag
end bag
max spill files
size
add
add all
add all
get memory size
round to eight
clear
compare to
equals
write
read fields
mark stale
to string
hash code
get spill file
report progress
warn
inc spill count
inc spill count
serial version u i d
amend key
amendable tuple
get amend key
set amend key
new default bag
new default bag
new sorted bag
new distinct bag
default bag factory
pkg
tup iter
key
m tuple factory
serial version u i d
read once bag
get memory size
spill
add
add all
clear
is distinct
is sorted
iterator
mark stale
size
read fields
write
compare to
equals
hash code
serial version u i d
log
file list
file list
file list
finalize
serial version u i d
log
g tuple factory
m read started
cache limit
max mem usage
mem usage
internal distinct bag
internal distinct bag
internal distinct bag
init
is sorted
is distinct
size
iterator
add
add all
add all
spill
serial version u i d
log
cache limit
max mem usage
mem usage
out
add done
factory
num tuples spilled
internal cached bag
internal cached bag
internal cached bag
init
add
update spill rec counter
add all
add all
add done
clear
is distinct
is sorted
iterator
spill
m tuple factory
m bag factory
unsigned short max
u t f 8
bytes to tuple
bytes to bag
bytes to map
bytes to internal map
bytes to char array
bytes to big char array
bytes to writable
read datum
read datum
write datum
serial version u i d
m data
data byte array
data byte array
data byte array
data byte array
data byte array
size
get
set
set
append
to string
compare to
compare
equals
hash code
serial version u i d
g tuple factory
log
default data bag
default data bag
is sorted
is distinct
iterator
spill
serial version u i d
m contents
non spillable data bag
non spillable data bag
non spillable data bag
is sorted
is distinct
iterator
report progress
add
add all
clear
mark stale
size
get memory size
spill
write
read fields
equals
hash code
compare to
to string
serial version u i d
log
default delimiter
timestamp
heartbeat
get time stamp
set time stamp
is heart beat
set heart beat
timestamped tuple
timestamped tuple
tuple raw comparator class
serial version u i d
t
target ops
is null
targeted tuple
targeted tuple
to string
write
read fields
to tuple
get target ops
set target ops
append
get
get all
get memory size
get type
is null
reference
set
size
to delimited string
compare to
equals
hash code
is null
set null
boolean true
boolean false
byte
integer
i n t e g e r 0
i n t e g e r 1
integer inshort
integer inbyte
long
float
double
bytearray
smallbytearray
tinybytearray
chararray
smallchararray
map
smallmap
tinymap
tuple
smalltuple
tinytuple
bag
smallbag
tinybag
generic writablecomparable
internalmap
null
m tuple factory
m bag factory
unsigned short max
unsigned byte max
u t f 8
read tuple
get tuple size
read bag
read map
read internal map
read char array
read big char array
read writable
read datum
read bytes
read datum
write datum
write map
write bag
write tuple
add cols to tuple
get tuple raw comparator class
instance
get inter sedes instance
g self
g mem mgr
get instance
new default bag
new default bag
new sorted bag
new distinct bag
bag factory
register bag
reset self
serial version u i d
buffer
index
accumulative bag
add
add all
clear
is distinct
is sorted
get tuplebuffer
iterator
mark stale
size
get memory size
spill
read fields
write
compare to
equals
hash code
g self
get instance
new tuple
new tuple
new tuple
new tuple no copy
new tuple
tuple class
tuple factory
reset self
tuple raw comparator class
serial version u i d
g tuple factory
log
m comp
m read started
sorted data bag
is sorted
is distinct
iterator
spill
serial version u i d
item
single tuple bag
add
add all
clear
is distinct
is sorted
iterator
mark stale
size
get memory size
spill
read fields
write
compare to
equals
hash code
to string
serial version u i d
sedes
write
read fields
bin sedes tuple
bin sedes tuple
bin sedes tuple
bin sedes tuple
get comparator class
serial version u i d
internal map
internal map
serial version u i d
proactive spill
serial version u i d
g tuple factory
log
m comp
m read started
cache limit
max mem usage
mem usage
internal sorted bag
internal sorted bag
internal sorted bag
internal sorted bag
init
add
add all
add all
is sorted
is distinct
iterator
spill
is null
serial version u i d
m fields
default tuple
default tuple
default tuple
default tuple
reference
size
is null
get type
get
get all
set
append
get memory size
round to eight
to delimited string
to string
compare to
equals
hash code
write
read fields
get field memory size
is null
set null
get comparator class
serial version u i d
log
g tuple factory
distinct data bag
is sorted
is distinct
size
iterator
add
add all
spill
serial version u i d
log
job name
job name prefix
job priority
exec type
extra jars
skip jars
dfs
lfs
execution engine
properties
script files
script jars
defined functions
defined commands
package import list
log 4j properties
default log level
default parallel
in explain
last alias
skipped ship paths
pig context
pig context
initialize import list
connect
set jobtracker location
add script file
add jar
add jar
rename
copy
get execution engine
get dfs
get lfs
get fs
get properties
get conf
get last alias
set last alias
register function
register stream cmd
get exec type
create cl
resolve class name
instantiate func from spec
instantiate func from spec
get class for alias
instantiate func from alias
get command for alias
set exec type
create executable manager
get func spec from alias
add path to skip
get paths to skip
get error source
get package import list
set package import list
set log 4j properties
get log 4j properties
get default log level
set default log level
factory
get mem num rows
exec
get return type
scalarfilename
value
exec
default num groups
num groups
r
g f any
g f any
exec
num samples
loader
record reader
sample loader
set num samples
get num samples
get input format
skip next
compute samples
get load caster
relative to absolute path
prepare to read
set location
set u d f context signature
partition list
total reducers
default percent memusage
log
m bag factory
m tuple factory
current index 
total reducers 
total memory 
input file 
total sample count 
heap percentage 
tuple m count 
partition skewed keys
partition skewed keys
exec
calculate reducers
get memory size
has same key
log
index file
index file load func spec
loader
index
right loader func spec
scope
dummy tuple
m tuple factory
inp location
default indexable loader
seek near
init right loader
extract keys from idx tuple
gen key
get next
close
initialize
get input format
get load caster
prepare to read
set location
set index file
quantiles list
weighted parts
m bag factory
m tuple factory
m asc
m state
m comparator
m user comparison func spec
m user comparison func
instantiate func
read object
find quantiles
find quantiles
exec
are equal
samples
next sample idx
random sample loader
get next
prepare to read
get sample
exec
output schema
num inputs
my number
num groups per input
m bag factory
m tuple factory
default parallelism
exec
to tuple
next
numrows tuple marker
num rows sampled
avg tuple mem sz
row num
skip interval
mem to skip per sample
num row spl tuple returned
sample rate
default sample rate
sample rate
perc mem avail
heap perc
new sample
poisson sample loader
get next
update skip interval
create num row tuple
compute samples
prepare to read
m tuple factory
m bag factory
num groups
g f replicate
g f replicate
exec
m log
rec reader
rec writer
inter storage
get next
put next
get input format
hash code
prepare to read
set location
get output format
prepare to write
set store location
check schema
rel to abs path for store location
get partition keys
get schema
get statistics
set partition filter
set store func u d f context signature
cleanup on failure
m factory
nullable bag
nullable bag
get value as pig type
nullable boolean writable
nullable boolean writable
get value as pig type
log
local prefix
style unix
style windows
r
to delete
relative root
local temp dir
check default prefix
open d f s file
open d f s file
get size
get size
open d f s file
get file element descriptors
open l f s file
open
full path
open
open
create
create
delete
to delete
set initialized
relative root
delete temp files
get temporary path
get temporary path
hadoopify
full path
file exists
file exists
is file
is file
is directory
is directory
glob matches files
get r
set r
parse cyg path
fetch file
k e y 0
sedes
writer
file out
t file record writer
close
write
start
pos
end
in
value
r e c o r d 1
r e c o r d 2
r e c o r d 3
in data
sedes
initialize
next key value
get current key
get current value
get progress
close
create record reader
partition index
key
nullable partition writable
nullable partition writable
set key
get key
set partition
get partition
compare to
read fields
write
is null
set null
get index
set index
get value as pig type
hash code
to string
nullable float writable
nullable float writable
get value as pig type
get record writer
start
pos
end
in
value
r e c o r d 1
r e c o r d 2
r e c o r d 3
in data
initialize
next key value
get current key
get current value
get progress
close
r e c o r d 1
r e c o r d 2
r e c o r d 3
out
bin storage record writer
close
write
nullable bytes writable
nullable bytes writable
get value as pig type
file
append
pig file
pig file
load
store
to string
nullable double writable
nullable double writable
get value as pig type
m log
rec reader
rec writer
t file storage
get next
put next
get input format
hash code
prepare to read
set location
get output format
prepare to write
set store location
check schema
rel to abs path for store location
get partition keys
get schema
get statistics
set partition filter
set store func u d f context signature
cleanup on failure
nullable text
nullable text
nullable text
get value as pig type
nullable unknown writable
nullable unknown writable
get value as pig type
m factory
nullable tuple
nullable tuple
get value as pig type
mq flag
idx space
m null
m value
m index
compare to
read fields
write
is null
set null
get index
set index
get value as pig type
hash code
equals
to string
nullable int writable
nullable int writable
get value as pig type
serial version u i d
file name
func spec
file spec
get file name
get func spec
to string
get func name
get size
equals
hash code
start
pos
end
reader
scanner
value
file in
sedes
initialize
next key value
get current key
get current value
get progress
close
r e c o r d 1
r e c o r d 2
r e c o r d 3
sedes
out
inter record writer
close
write
wrapped load func
conf
input location
to read splits
to read splits idx
cur split index
inp splits
reader
input format
read to end loader
read to end loader
init
initialize reader
get next
get next helper
update cur split index
get input format
get load caster
prepare to read
set location
nullable long writable
nullable long writable
get value as pig type
pos
in
buf size
barray
bbuff
carray
cbuff
buffered positioned input stream
buffered positioned input stream
read
read
skip
get position
read line
close
serial version u i d
relational operator
relational operator
get projection map
unset projection map
regenerate projection map
get required fields
get relevant inputs
prune columns
prune column in plan
insert plain for each after
m cast list
cast finder
visit
get cast list
get cast set
found any cast
serial version u i d
log
l o multiply
get schema
get field schema
visit
name
serial version u i d
l o define
get schema
visit
name
supports multiple inputs
serial version u i d
m input file spec
m load func
m schema file
m enforced schema
conf
log
m determined schema
script schema
required field list
m determined schema cached
l o load
get input file
set input file
get schema file
get load func
name
get schema
determine schema
set schema
supports multiple inputs
visit
get enforced schema
set enforced schema
get type
get determined schema
get projection map
get required fields
get relevant inputs
push projection
set alias
prune columns
get required field list
get configuration
serial version u i d
log
l o greater than
get schema
get field schema
visit
name
m op to clone map
logical plan clone helper
logical plan clone helper
get cloned plan
reset state
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
plan setter
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
remove redundant operators
visit
patch input reference
serial version u i d
binary expression operator
binary expression operator
get lhs operand
get rhs operand
visit
supports multiple inputs
clone
partition cols
p col conditions
saw key
saw non key col
replace side
filter removable
visit
p col filter extractor
visit
visit
get p col condition
is filter removable
check successors
check successors helper
replace child
remove
get expression
get expression
throw exception
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
serial version u i d
m load func spec
user specified field schema
l o cast
get expression
visit
get schema
set field schema
get field schema
name
supports multiple inputs
get load func spec
set load func spec
clone
serial version u i d
native m r jar
params
l o native
get relevant inputs
get native m r jar
get params
visit
name
supports multiple inputs
get schema
project star translator
visit
visit
visit
visit
check plan for project star
get project star from plan
translate project star in plan
replicate plan
add successors
replace project star
serial version u i d
log
m is field schema computed
m field schema
expression operator
expression operator
supports multiple outputs
get schema
get field schema
set field schema
unset field schema
regenerate field schema
set field schema computed
get field schema computed
get type
clone
serial version u i d
log
l o lesser than equal
get schema
get field schema
visit
name
serial version u i d
log
l o mod
get schema
get field schema
visit
name
serial version u i d
m output file
m input spec
signature
m store func
log
is tmp store
sort info
is tmp store
set tmp store
get sort info
set sort info
l o store
construct signature
get output file
set output file
get store func
name
get schema
supports multiple inputs
supports multiple outputs
visit
set input spec
get input spec
get projection map
get required fields
get relevant inputs
set alias
get signature
serial version u i d
log
l o add
get schema
get field schema
visit
name
serial version u i d
m func spec
implicit referenced operator
l o user func
get func spec
get implicit referenced operator
set implicit referenced operator
get arguments
supports multiple inputs
name
get schema
get field schema
visit
set func spec
clone
serial version u i d
log
unary expression operator
unary expression operator
get operand
visit
supports multiple inputs
clone
serial version u i d
log
m schema input mapping
l o cross
get inputs
get schema
name
supports multiple inputs
visit
get type
get projection map
get required fields
get relevant inputs
serial version u i d
log
l o or
get schema
get field schema
visit
name
serial version u i d
m exp
m projection
m is star
log
m sentinel
m overloaded
send empty bag on e o p
l o project
l o project
get expression
set expression
is star
get projection
set projection
get col
set star
get sentinel
set sentinel
get overloaded
set overloaded
name
supports multiple inputs
get field schema
is single projection
visit
get schema
to detail string
clone
set send empty bag on e o p
is send empty bag on e o p
m u d f list
u d f finder
visit
get u d f list
get u d f set
found any u d f
m project list
top level project finder
visit
visit
visit
visit
visit
get project list
get project set
get project star set
serial version u i d
command
executable manager
is parent set
l o stream
get streaming command
get schema
set optimized spec
visit
name
supports multiple inputs
get executable manager
get projection map
get required fields
get relevant inputs
serial version u i d
log
is on schema
l o union
get inputs
get schema
create merged schema on alias
name
supports multiple inputs
visit
get type
clone
get projection map
get required fields
get relevant inputs
prune columns
set on schema
is on schema
serial version u i d
log
l o distinct
get input
get schema
name
supports multiple inputs
visit
get type
clone
get projection map
get required fields
get relevant inputs
serial version u i d
log
l o subtract
get schema
get field schema
visit
name
serial version u i d
m generate plans
m flatten
m user defined schema
log
l o generate
l o generate
l o generate
get generate plans
get flatten
get user defined schema
name
supports multiple inputs
get schema
visit
clone
l o visitor
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
m nid
scope
get new name
pruned columns map
plan
column pruner
add prune map
is empty
prune
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
serial version u i d
log
l o equal
get schema
get field schema
visit
name
serial version u i d
m outputs
log
l o split
get outputs
set outputs
add output
name
get schema
supports multiple inputs
supports multiple outputs
visit
get type
clone
get projection map
get required fields
rewire
get relevant inputs
serial version u i d
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
frontend exception
serial version u i d
m value
l o const
get value
visit
get schema
get field schema
name
supports multiple inputs
supports multiple outputs
clone
current op
in op
m scalar map
scalar finder
visit
visit
visit
visit
visit
visit
get scalar map
serial version u i d
log
l o divide
get schema
get field schema
visit
name
serial version u i d
log
l o is null
get schema
get field schema
visit
name
m new node
m old node
m predecessor index
m use old node
m containing node
m projection mapping
project fixer upper
project fixer upper
visit
visit
visit
visit
visit
visit
visit
to string
serial version u i d
log
l o regexp
get operand
get regexp
name
supports multiple inputs
get schema
get field schema
visit
serial version u i d
log
l o and
get schema
get field schema
visit
name
serial version u i d
l o bin cond
get cond
get lhs op
get rhs op
visit
get schema
get field schema
name
supports multiple inputs
clone
serial version u i d
m limit
l o limit
get input
get limit
set limit
get schema
name
supports multiple inputs
supports multiple outputs
visit
get type
duplicate
clone
get projection map
get required fields
get relevant inputs
classloader
pig context
logical plan builder
parse
parse
serial version u i d
log
l o not equal
get schema
get field schema
visit
name
m stream
t a b 1
t a b more
l sep
u sep
level cntr
is verbose
l o printer
visit
set verbose
print
depth first l p
plan string
plan string
depth first
shift string by tabs
disp tabs
serial version u i d
m schema
m is schema computed
m type
m requested parallelism
m alias
m plan
m projection map
m is projection map computed
m pinned options
m custom partitioner
log
get custom partitioner
set custom partitioner
logical operator
logical operator
get operator key
set schema
set parent
force schema
unset schema
regenerate schema
set canonical names
get schema
set type
get type
get alias
get alias string
set alias
get requested parallelism
set requested parallelism
pin option
is pinned option
to string
reconcile schema
visit
get plan
set plan
set schema computed
supports multiple outputs
clone
serial version u i d
logical plan
get single leaf plan output op
get single leaf plan output type
explain
explain
clone
chain of projects
serial version u i d
m is inner
log
m group by plans
m group type
option grouptype
l o cogroup
l o cogroup
get inputs
get group by plans
set group by plans
get inner
set inner
get group type
name
supports multiple inputs
get schema
is tuple group col
visit
switch group by plan op
unset schema
get atomic group by type
get tuple group by schema
set field schema parent
set field schema parent
clone
get projection map
get required fields
rewire
get relevant inputs
prune columns
serial version u i d
log
m join plans
m inner flags
m join type
m schema input mapping
option join
l o join
get copy
get inputs
get join plans
set join plans
get join type
name
supports multiple inputs
get schema
is tuple join col
visit
switch join col plan op
unset schema
get atomic join col type
get tuple join schema
clone
get projection map
get required fields
rewire
get relevant inputs
get inner flags
prune columns
serial version u i d
l o negative
get schema
get field schema
visit
name
serial version u i d
m comparison plan
log
l o filter
get input
get comparison plan
get schema
name
supports multiple inputs
visit
get type
unset schema
clone
get projection map
get required fields
rewire
get relevant inputs
prune columns
projection map remover
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
dot l o printer
dot l o printer
make dumper
get name
get attributes
get multi input nested plans
get nested plans
projection map calculator
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
serial version u i d
log
l o greater than equal
get schema
get field schema
visit
name
pig context
union on schema setter
visit
get next id
serial version u i d
m asc cols
m sort func
m is star
limit
m sort col plans
log
l o sort
get input
get sort col plans
set sort col plans
get ascending cols
set ascending cols
get user func
set user func
is star
set star
set limit
get limit
is limited
name
get schema
supports multiple inputs
visit
get type
clone
get projection map
get required fields
rewire
get sort info
get relevant inputs
prune columns
m plan
logical plan cloner
get cloned plan
serial version u i d
m for each plans
m flatten
m user defined schema
log
m schema plan mapping
l o for each
l o for each
get for each plans
set for each plans
get flatten
set flatten
get user defined schema
set user defined schema
name
supports multiple inputs
visit
get type
update alias count
get schema
unset schema
do all successors
dump nested schema
clone
get projection map
get required fields
rewire
has flatten
get relevant plan
is input flattened
get relevant inputs
prune columns
serial version u i d
m map key
m value type
m value schema
log
l o map lookup
get map
get look up key
get value type
name
supports multiple inputs
get schema
get field schema
visit
clone
serial version u i d
log
l o lesser than
get schema
get field schema
visit
name
serial version u i d
log
l o not
get schema
get field schema
visit
name
serial version u i d
m index
m cond plan
log
l o split output
get condition plan
name
get schema
visit
supports multiple inputs
get read from
get type
unset schema
clone
get projection map
get required fields
rewire
get relevant inputs
prune columns
implicit split inserter
check
transform
m swap
m push before
m push before input
push up filter
get swap
get push before
get push before input
check
get operator
transform
reset
is any outer
is required field mapped
is field simple
log
mode
op limit optimizer
op limit optimizer
check
transform
process node
schema calculator
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
m swap
m insert between
m flattened column re map
push down foreach flatten
get swap
get insert between
get flattened column map
check
get operator
transform
reset
schema remover
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
scope
node id gen
m rules off
prune rule
logical optimizer
logical optimizer
logical optimizer
run optimizations
rule enabled
check and add rule
optimize
partition keys
load metadata
load func
lo load
lo filter
already checked
col name map
reverse col name map
partition filter optimizer
check
transform
update mapped col names
get mapped keys
setup col name maps
log
logical transformer
rebuild schemas
rebuild projection maps
insert between
fix up contained plans
insert after
reset
operator class name
type cast inserter
check
get operator
transform
safe to prune
log
cached required info
pruned loader columns map
pruner
prune columns
check
transform
process node
get map keys in plan
is simple project cast
prune loader
prune
serial version u i d
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
schema merge exception
serial version u i d
m fields
m aliases
m field schemas
log
two level access required
prime list
schema
schema
schema
schema
copy and link
get field
get field sub name match
get field
size
reconcile
equals
clone
hash code
to string
stringify schema
add
get position
get position sub name
get position
add alias
get aliases
print aliases
get fields
castable
equals
merge
merge schema
merge schema
merge alias
merge schemas by alias
merge schema by alias
check null alias
merge field schema first level same alias
merge name spaced alias
get field sub name match throw schema merge exception
generate nested schema
merge prefix schema
merge prefix schema
set schema default type
is two level access required
set two level access required
get pig schema
find field schema
supported type set
new tuple schema
new tuple schema
new tuple schema
new tuple schema
new tuple schema
new tuple schema
new names
new bag schema
new bag schema
new bag schema
new bag schema
new bag schema
new bag schema
check data types
check parameters
serial version u i d
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
union on schema set exception
pig ctx
input output file validator
validate
pig ctx
msg collector
input output file visitor
visit
inf
log
msg collector
strict mode
current alias
cast lookup
type checking visitor
visit
visit
visit
resolve l o project type
visit
visit
visit
insert cast for regexp
visit
insert casts for null to boolean
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
insert left cast for binary op
insert right cast for binary op
insert cast
insert cast for u d f
visit
insert cast for uni op
visit
exact match with byte arrays
exact match
best fit match
best fit match with byte arrays
byte array found
get byte array positions
exact match helper
schema equals for matching
fit possible
insert casts for u d f
visit
insert left cast for bin cond
insert right cast for bin cond
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
insert atomic cast for join inner plan
insert atomic cast for c o group inner plan
get atomic group by type
get tuple group by schema
visit
check inner plan
visit
visit
insert cast for each in between if necessary
collect cast warning
gen new operator key
get load func spec
get load func spec
generate incompatible types message
schema alias validator
validate
serial version u i d
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checker exception
type checking validator
validate
validator list
logical plan validation executor
validate
schema alias visitor
validate
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
m need all fields
m need no fields
m fields
m map keys info list
required fields
required fields
required fields
required fields
get fields
get field
size
set fields
need all fields
get need all fields
set need all fields
need no fields
get need no fields
set need no fields
to string
merge
re index
merge map key
merge map keys info
set map keys info
get map keys info
set map keys info
serial version u i d
m key
operator
get operator key
visit
supports multiple inputs
supports multiple outputs
name
to string
equals
hash code
compare to
clone
get projection map
unset projection map
regenerate projection map
rewire
keys
need all keys
map keys info
map keys info
map keys info
map keys info
get keys
need all keys
to string
scope to id map
the generator
node id generator
get generator
get next node id
reset
dependency order walker w o seen chk
walk
spawn child walker
do all predecessors
dependency order walker
walk
spawn child walker
do all predecessors
m plan
plan walker
walk
spawn child walker
get plan
set plan
m stream
t a b 1
t a b more
l sep
level cntr
plan printer
visit
print
depth first
depth first
shift string by tabs
disp tabs
m ops
m keys
m from edges
m to edges
m soft from edges
m soft to edges
m roots
m leaves
log
operator plan
get roots
get leaves
get operator key
get operator
get keys
add
connect
create soft link
remove soft link
disconnect
remove
trim below
trim below
trim above
trim above
get predecessors
get successors
get soft link predecessors
get soft link successors
path exists
iterator
mark dirty
remove edges
check in plan
merge
merge shared plan
do merge
add as leaf
is single leaf plan
size
insert between
do insert between
replace node
replace
generate new map
remove and reconnect
reconnect successors
reconnect predecessors
replace and add sucessors
replace and add predecessors
remove and reconnect multi succ
dump
explain
swap
push before
push after
serial version u i d
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
plan exception
serial version u i d
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
visitor exception
serial version u i d
scope
id
operator key
operator key
to string
equals
hash code
get scope
get id
compare to
gen op key
serial version u i d
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
plan validation exception
m changes
m mapped fields
m removed fields
m added fields
projection map
projection map
projection map
get mapped fields
set mapped fields
get removed fields
set removed fields
get added fields
set added fields
changes
get changes
set changes
to string
m plan
m current walker
m walkers
visit
get plan
plan visitor
push walker
pop walker
validate
validate
validate tolerate exception
validate skip collect exception
depth first walker
walk
spawn child walker
depth first
m subgraphs
m multi input subgraphs
m multi output subgraphs
is sub graph
dot plan dumper
dot plan dumper
dump
dump multi input nested operator
dump multi output nested operator
dump nested operator
dump operator
dump edge
make dumper
get name
get attributes
connect invisible input
connect invisible input
connect invisible output
connect invisible
dump invisible input
dump invisible input
dump invisible output
dump invisible operators
get cluster i d
get cluster i d
get subgraph i d
get subgraph i d
get i d
get invisible attributes
dump invisible edge
reverse dependency order walker
walk
spawn child walker
do all successors
message list
compilation message collector
collect
collect
has message type
has error
iterator
has message
size
get
get kind aggregate
log aggregate
log messages
log messages
log all messages
log all messages
log message
ps
plan
is verbose
plan dumper
set verbose
is verbose
dump
make dumper
dump operator
dump multi input nested operator
dump multi output nested operator
dump nested operator
dump edge
get multi input nested plans
get multi output nested plans
get nested plans
join
serial version u i d
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
optimizer exception
serial version u i d
log
m node class
m node type
rule operator
rule operator
set node type
get node type
get node class
to string
visit
supports multiple outputs
supports multiple inputs
clone
name
m common nodes
common node finder
get count
get common nodes
reset
visit
visit
m rule plan
m transformer
m walker algo
m rule name
rule
rule
get plan
get transformer
get rule name
get walker algo
m stream
t a b 1
t a b more
l sep
level cntr
rule plan printer
visit
print
depth first
depth first
shift string by tabs
disp tabs
m rules
m plan
m max iterations
plan optimizer
plan optimizer
optimize
m rule
m match
m prelim matches
m matches
m plan
m num common nodes
match
reverse dependency order walker
r d o do all successors
dependency order walker
process preliminary matches
get common nodes from match
b f s do all predecessors
depth first walker
d f s visit
get matches
get all matches
begin match
continue match
serial version u i d
rule plan
explain
m plan
transformer
check
transform
reset
get plan
rule plan visitor
visit
deserializer
in
istream
already closed
get output type
bind to
get next
close
file name
file output handler
get output type
bind to
serializer
out
already closed
get input type
put next
close
bind to
file out stream
file input handler
get input type
bind to
close
log
success
path
bash
eos result
command
argv as string
process
exit code
stdin
stdin thread
stdout thread
stdout
stderr thread
stderr
input handler
output handler
input records
input bytes
output records
output bytes
outerr threads error
po stream
file input thread
executable manager
configure
close
kill process
setup environment
exec
run
send output
process error
serial version u i d
executable
argv
ship spec
cache spec
handle specs
persist stderr
log dir
log files limit
max tasks
ship files
pig context
streaming command
get executable
set executable
set command args
get command args
get ship specs
get cache specs
add path to ship
add path to cache
add handle spec
set input spec
get input spec
set output spec
get output spec
get handle specs
get persist stderr
set persist stderr
get log dir
set log dir
get log files limit
set log files limit
set ship files
get ship files
to string
clone
default input handler
default input handler
get input type
close
default output handler
default output handler
get output type
create input handler
create output handler
map
add
add all
clear
contains
contains all
is empty
iterator
remove
remove all
retain all
size
to array
to array
to string
is h d f s file
is h d f s file or local
log
pig packages to send
create jar
create cl
merge jar
merge jar
merge jar
add stream
add containing jar
find containing jar
u t f 8
parse field del
put field
text to tuple
read field
parse single quoted string
serial version u i d
first
second
pair
to string
hash code
equals
it
buf
pos
no rewind
rewindable iterator
has next
has next
rewind
no rewind
next
warn
get permission exception
get pig exception
write log
write log
write log
log
serialize
deserialize
encode bytes
decode bytes
default properties file
properties file
log
load default properties
load properties from file
load properties from classpath
load default properties
parents
counts
ranks
insert
union
get representative
link
get counts
get weighted counts
get members
get membership map
m log
format
check null equals
check null and class
get schema
get schema from string
get schema from string
get tmp file compressor name
get tmp file storage object
tmp file compression
tmp file compression codec
get string from array
build simple func spec
slashisize
merge collection
format
serial version u i d
m map
multi map
multi map
put
put
get
remove
remove key
key set
values
to string
size
is empty
clear
contains key
contains value
jconf
udf confs
client sys props
client sys props
udf context
self
u d f context
get u d f context
set client system props
get client system props
add job conf
get job conf
get u d f properties
get u d f properties
serialize
deserialize
generate key
generate key
reset
is u d f conf empty
serial version u i d
linked multi map
linked multi map
wrap
wrap
m max int
m max long
m log
string to double
string to float
string to integer
string to long
unescape input string
join
get path strings
add empty bag outer join
log
spillables
gc activation size
spill file size threshold
accumulated free size
memory threshold fraction
collection memory threshold fraction
first usage thresh exceeded logged
first collection thresh exceeded logged
spillable memory manager
configure
handle notification
register spillable
log
validate pig properties
get validated properties
ensure long type
depth first walker
spawn child walker
walk
depth first
serial version u i d
plan edge
plan edge
put
remove with position
default scope
plan
current walker
walkers
visit
get plan
plan visitor
push walker
pop walker
base plan
roots
leaves
operators
operator sub plan
get base plan
add
connect
connect
disconnect
get sinks
get operators
get predecessors
get sources
get successors
remove
size
is equal
create soft link
remove soft link
get soft link predecessors
get soft link successors
insert between
remove and reconnect
replace
plan
plan walker
walk
spawn child walker
get plan
set plan
reverse dependency order walker
spawn child walker
walk
do all successors
ops
from edges
to edges
soft from edges
soft to edges
roots
leaves
log
base operator plan
size
get sources
get sinks
get predecessors
get successors
get soft link predecessors
get soft link successors
add
remove
connect
connect
create soft link
remove soft link
disconnect
mark dirty
get operators
is equal
check predecessors
is equal
explain
to string
replace
remove and reconnect
insert between
reverse dependency order walker w o seen chk
spawn child walker
walk
do all successors
dependency order walker
spawn child walker
walk
do all predecessors
name
plan
annotations
hash prime
operator
accept
get name
get plan
annotate
get annotation
remove annotation
set plan
is equal
partition cols
p col conditions
saw key
saw non key col
replace side
filter removable
visit
p col filter extractor
visit
visit
get p col condition
is filter removable
check successors
check successors helper
replace child
replace
remove
remove tree
get expression
get expression
throw exception
visit
visit
visit
visit
visit
visit
visit
start node
subtree dependency order walker
subtree dependency order walker
walk
expr plan
expr ops map
attached relational op
old attached relational op
outer plan
outer ops map
logical exp plan migration vistor
translate connection
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
new inner plan
old foreach
gen
input no
inner ops map
outer ops map
foreach inner plan visitor
translate inner plan connection
translate inner expression plan
visit
visit
visit
visit
visit
visit
translate schema
translate field schema
translate schema
translate field schema
add for each after
logical plan
ops map
logical plan migration vistor
translate connection
translate expression plan
get new logical plan
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
not expression
accept
is equal
get field schema
deep copy
m func spec
implicit referenced operator
ef
user func expression
get func spec
accept
is equal
get arguments
set func spec
get field schema
get implicit referenced operator
set implicit referenced operator
deep copy
to string
is null expression
accept
is equal
get field schema
deep copy
negative expression
accept
is equal
get field schema
deep copy
unary expression
get expression
divide expression
accept
is equal
get field schema
deep copy
next uid
field schema
uid only field schema
get next uid
reset next uid
logical expression
get field schema
reset field schema
get type
to string
never use for real set field schema
deep copy
reset uid
subtract expression
accept
is equal
get field schema
deep copy
is equal
explain
merge
deep copy
input
col
attached relational op
project expression
accept
get input num
set input num
get col num
set col num
is project star
get field schema
find referent
is equal
to string
get attached relational op
set attached relational op
get type
deep copy
current op
log to phy map
current plans
current plan
node gen
pc
exp to phy translation visitor
exp to phy translation visitor
set pig context
get physical plan
attach binary comparison operator
attach binary expression operator
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
add expression
accept
is equal
get field schema
deep copy
equal expression
accept
is equal
get field schema
deep copy
cast func
cast schema
cast expression
accept
set func spec
get func spec
is equal
get field schema
deep copy
mod expression
accept
is equal
get field schema
deep copy
val
m value schema
constant expression
accept
get value
get value schema
is equal
get field schema
deep copy
greater than equal expression
accept
is equal
get field schema
deep copy
less than equal expression
accept
is equal
get field schema
deep copy
columns
dereference expression
dereference expression
accept
get bag columns
set bag columns
is equal
get referred expression
to string
get field schema
deep copy
less than expression
accept
is equal
get field schema
deep copy
logical expression visitor
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
regex expression
accept
is equal
get field schema
deep copy
binary expression
get lhs
get rhs
and expression
accept
is equal
get field schema
deep copy
not equal expression
accept
is equal
get field schema
deep copy
greater than expression
accept
is equal
get field schema
deep copy
m map key
m value schema
map lookup expression
accept
is equal
get map
get lookup key
get field schema
to string
deep copy
all same expression visitor
execute
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
bin cond expression
get condition
get lhs
get rhs
accept
is equal
get field schema
deep copy
multiply expression
accept
is equal
get field schema
deep copy
or expression
accept
is equal
get field schema
deep copy
column expression
uid resetter
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
m rules off
logical plan optimizer
build rule sets
check and add rule
add listeners
transformed
all same ralational nodes visitor
execute
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
m stream
t a b 1
t a b more
l sep
u sep
seperate
logical plan printer
visit
depth first l p
depth first
reverse depth first l p
reverse depth first
plan string
print node
shift string by tabs
expr visitor
current op
all expression visitor
get visitor
visit
visit
visit
visit
visit
visit
visit
visit
transformed
schema resetter
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
serial version u i d
m join plans
m inner flags
m join type
l o join
l o join
is inner
get inner flags
get join type
get join plan
get expression plans
get expression plan values
get schema
accept
is equal
m limit
serial version u i d
l o limit
get limit
set limit
get schema
accept
is equal
m asc cols
m sort func
m is star
limit
m sort col plans
l o sort
get sort col plans
set sort col plans
get ascending cols
set ascending cols
get user func
set user func
is star
set star
set limit
get limit
is limited
get schema
accept
get sort info
is equal
serial version u i d
output
m input spec
signature
is tmp store
sort info
store func
l o store
l o store
get output spec
get store func
get schema
accept
is equal
get sort info
set sort info
is tmp store
set tmp store
set input spec
get input spec
get signature
set signature
log to phy map
current plans
current plan
node gen
pc
log to phy translation visitor
set pig context
get physical plan
visit
visit
visit
visit
visit
visit
visit
visit
translate expression plans
visit
visit
translate collected cogroup
compile to merge cogrp
translate merge cogroup
validate merge cogrp
validate map side merge
visit
compile to l r g r pack trio
compile f e 4 flattening
visit
visit
visit
visit
visit
update with empty bag check
validate merge join
merge join validator
translate soft links
is equal
explain
m is inner
m expression plans
m group type
group key uid only schema
generated input uids
group col name
l o cogroup
l o cogroup
l o cogroup
get plan schema
get schema
accept
is equal
get group type
get generated input uids
get expression plans
get inner
reset uid
script schema
serial version u i d
command
executable manager
uid only schema
cast inserted
l o stream
get streaming command
get executable manager
get schema
accept
is equal
set cast inserted
is cast inserted
reset uid
serial version u i d
l o distinct
get schema
accept
is equal
serial version u i d
filter plan
l o filter
l o filter
get filter plan
set filter plan
get schema
accept
is equal
serial version u i d
l o cross
get schema
accept
is equal
filter plan
uid mapping
l o split output
l o split output
get filter plan
set filter plan
get schema
accept
is equal
reset uid
get input uids
output plans
flatten flags
m user defined schema
output plan schemas
uid only schemas
l o generate
get schema
get output plans
get flatten flags
set flatten flags
is equal
accept
to string
get user defined schema
set user defined schema
get output plan schemas
set output plan schemas
get uid only schemas
set uid only schemas
reset uid
l o split
get schema
accept
is equal
script schema
fs
load func
conf
determined schema
required fields
cast inserted
uid only schema
l o load
get load func
set script schema
set required fields
get schema
get schema from meta data
get file spec
accept
get determined schema
is equal
set cast inserted
is cast inserted
get configuration
reset uid
native m r jar
params
l o native
get schema
accept
is equal
get native m r jar
set native m r jar
get params
set params
fields
aliases
two level access required
logical schema
add field
get field
get field
get fields
size
is equal
find field
merge
to string
to string
set two level access required
is two level access required
merge uid
deep copy
uid mapping
l o union
get schema
accept
is equal
get input uids
reset uid
serial version u i d
schema not defined exception
schema not defined exception
schema not defined exception
serial version u i d
inner plan
l o for each
get inner plan
set inner plan
is equal
get schema
accept
find reacheable inner load from boundary project
schema
requested parallelism
alias
line num
m custom partitioner
logical relational operator
logical relational operator
get schema
set schema
reset schema
reset uid
get requested parallelisam
get alias
set alias
set requested parallelism
get line number
never use for real set schema
check equality
to string
get custom partitioner
set custom partitioner
logical relational nodes visitor
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
prj
foreach
source is bag
l o inner load
get schema
get projection
is equal
accept
get col num
get l o for each
source is bag
to string
partition keys
load metadata
load func
lo load
lo filter
col name map
reverse col name map
partition filter optimizer
build pattern
get new transformer
log
group by const parallel setter
get new transformer
build pattern
sub plan
merge for each
build pattern
get new transformer
stream type cast inserter
get operator class name
size limit
explain
safe add
merge filter
get new transformer
build pattern
whole plan rule
match
build pattern
add for each
get new transformer
duplicate for each column rewrite
build pattern
get new transformer
required mapkeys
current plan
subplan
map keys prune helper
check
has map
get map uids
report changes
has run
column map key prune
get new transformer
type cast inserter
build pattern
get operator class name
get new transformer
pig ctx
plan
input output file validator
validate
dnf plan
result
d n f plan generator
get d n f plan
visit
remove descendants
merge simple or
merge and or
visit
add children
implicit split inserter
match
get new transformer
build pattern
push up filter
get new transformer
build pattern
split filter
get new transformer
build pattern
inputuids
outputuids
requiredcols
current plan
sub plan
column prune helper
get sub plan
add operator
check
clear annotation
get columns
report changes
logical expression simplifier
get new transformer
build pattern
push down for each flatten
build pattern
get new transformer
src
logical expression proxy
accept
is equal
get field schema
decr src d n f split counter
restore src
deep copy
filter above foreach
build pattern
get new transformer
result
const exp evaluator
binary expression const prune
unary expression const prune
no const prune
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
type
d n f expression
accept
is equal
get field schema
deep copy
limit optimizer
build pattern
get new transformer
find generate
has flatten
has flatten
load type cast inserter
get operator class name
log
required items
column prune
column prune visitor
add required items
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
remove sub tree
add for each if necessary
rule sets
plan
listeners
max iter
default iterations
plan optimizer
add plan transform listener
optimize
check
transform
report changes
name
pattern
current plan
log
matched nodes
mandatory
rule
rule
build pattern
get new transformer
get pattern
match
get name
is mandatory
match
derived data
phys plan
base data
log to phy map
log
op to eq classes
eq classes
lineage
derived data visitor
derived data visitor
set operator to evaluate
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
evaluate operator
evaluate isolated operator
evaluate isolated operator
log
local log to phy translation visitor
get log to phy map
visit
visit
visit
visit
visit
visit
visit
get equivalence classes
get equivalence classes
get equivalence classes
get equivalence classes
get equivalence classes
get equivalence classes
get equivalence classes
get equivalence classes
base data
new base data
derived data
output constraints map
log
augment base data visitor
get new base data
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
get group by input
back prop constraint
generate matching tuple
generate matching tuple
generate matching tuple helper
generate matching tuple helper
generate matching tuple helper
generate matching tuple helper
generate matching tuple helper
get unequal value
get smaller value
get larger value
generate data
plan
base data
log to phy map
phys plan
completeness
log
affinity groups
lineage
continue trimming
pc
lineage trimming visitor
init
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
prune base data constrained coverage
process operator
check completeness
plan
base data
pig context
log to phy map
phys plan
log
max records
example generator
set max records
get examples
read base data
compile plan
refine logical plan
serial version u i d
data
its
inner
p o cogroup
p o cogroup
p o cogroup
p o cogroup
set inner
visit
name
get next
accumulate data
get smallest
supports multiple inputs
supports multiple outputs
serial version u i d
input bags
data
its
p o cross
p o cross
p o cross
p o cross
visit
get next
accumulate data
create tuple
name
supports multiple inputs
supports multiple outputs
serial version u i d
data
processing done
p o split
p o split
p o split
p o split
get next
visit
name
supports multiple inputs
supports multiple outputs
serial version u i d
count
p o counter
p o counter
p o counter
p o counter
visit
get next
get next
name
supports multiple inputs
supports multiple outputs
get count
serial version u i d
p o stream local
get next
serial version u i d
comp op
comp plan
it
p o split output
p o split output
p o split output
p o split output
visit
get next
name
supports multiple inputs
supports multiple outputs
set plan
get realness
get conciseness
get completeness
get completeness logic
operator
dependency order limited walker
walk
max dataatom length
print metrics
print tabular
print tabular
print simple
add spaces
display table
make array
shorten field
shorten field
shorten field
pre order depth first walker
walk
spawn child walker
depth first
serial version u i d
synthetic
omittable
t
example tuple
example tuple
to string
write
read fields
to tuple
append
get
get all
get memory size
get type
is null
is null
reference
set
set null
size
to delimited string
compare to
scope
node id gen
functional logical optimizer
parents
counts
ranks
insert
union
get representative
link
get counts
get weighted counts
get members
get membership map
supported script langs
namespace separator
register functions
get jar path
get instance
function
schema
num parameters
script file path
output schema func
jython function
exec
output schema
tuple factory
bag factory
python to pig
pig to python
pig tuple to py tuple
register functions
get function
end of opts
m args
m short
m long
m arg num
m val
cmd line parser
register opt
get next opt
get remaining args
get val str
get val int
log
m pig server
m dfs
m lfs
m conf
m job conf
m done
m load only
m explain
m num failed jobs
m num succeeded jobs
shell
grunt parser
grunt parser
grunt parser
grunt parser
init
set batch on
execute batch
discard batch
parse stop on error
parse stop on error
set load only
set params
prompt
quit
is done
process describe
process explain
process explain
explain current batch
explain current batch
print aliases
process register
process register
run preprocessor
process script
load script
process set
process cat
process c d
process dump
process illustrate
process kill
process l s
print length and replication
process p w d
print help
process move
process copy
process copy to local
process copy from local
process mkdir
process pig
process remove
process fs command
process sh command
log
keywords
pig
pig completor aliases
complete
search candidate
execute
log
in
pig
parser
grunt
set console reader
run
exec
check script
log
candidates
autocomplete filename
pig completor
load candidate keywords
complete
is delimit
search candidate
pc
log
param parser
pig parser
parameter substitution preprocessor
gen substituted file
parse pig file
load params from file
load params from cmdline
param val
log
id pattern
preprocessor context
process shell cmd
process ord line
process shell cmd
process ord line
execute shell command
substitute
name
location
bytes
records
success
store
conf
output stats
get name
get location
get bytes
get number records
get function name
is successful
get alias
get p o store
get conf
get display string
set p o store
set conf
name
location
bytes
records
success
type
conf
input stats
get name
get location
get bytes
get number records
is successful
get conf
get input type
get display string
set conf
mark sample input
mark indexer input
mark side file input
multi store record counter
multi store counter group
task counter group
fs counter group
map input records
map output records
reduce input records
reduce output records
hdfs bytes written
hdfs bytes read
multi inputs record counter
multi inputs counter group
log
counter name limit
separator
semicolon
pattern
get multi store count
get multi store counter name
get multi inputs counter name
get short name
start collection
stop collection
get empty pig stats
get pig stats
display statistics
update job mro map
accumulate stats
set error message
set error code
set backend exception
is temp file
add failed job stats
add native job stats
add native job stats
accumulate success statistics
insert enabled
max script size
log
tss
id
script
command line
pig version
hodoop version
script features
feature map
alias map
listeners
start
script state
get
register listener
emit launch started notification
emit jobs submitted notification
emit job started notification
emitjob finished notification
emit job failed notification
emit output completed notification
emit progress updated notification
emit launch completed notification
add settings to conf
set script
set script
set script features
get hadoop version
get pig version
get id
get command line
set command line
get script
set script
set pig feature
set job parents
get script features
get alias
get pig feature
bit set to long
feature long to string
alias
feature
success header
failure header
success header local
log
state
conf
map stores
reduce stores
loads
outputs
inputs
error msg
exception
job id
max map time
min map time
avg map time
max reduce time
min reduce time
avg reduce time
number maps
number reduces
map input records
map output records
reduce input records
reduce output records
hdfs bytes written
hdfs bytes read
spill count
active spill count obj
active spill count recs
multi store counters
multi input counters
counters
job stats
get job id
get state
is successful
get error message
get exception
get number maps
get number reduces
get max map time
get min map time
get avg map time
get max reduce time
get min reduce time
get avg r educe time
get map input records
get map output records
get reduce output records
get reduce input records
get s m m spill count
get proactive spill count objects
get proactive spill count recs
get hdfs bytes written
get hadoop counters
get outputs
get inputs
get multi store counters
get alias
get feature
get bytes written
get record writtern
accept
is equal
set id
set successful
set error msg
set backend exception
set conf
set map stat
set reduce stat
get display string
add counters
add map reduce statistics
set alias
add output statistics
add one output stats
add input statistics
add one input stats
is sampler
is indexer
log
date format
tps
pig context
job client
jcc
job plan
job mro map
mro job map
start time
end time
user id
return code
error message
error code
get
start
is successful
get return code
get error message
get error code
get pig properties
get job graph
get output locations
get output names
get number bytes
get number records
get output alias
get s m m spill count
get proactive spill count objects
get proactive spill count records
get bytes written
get record written
get hadoop version
get pig version
get script id
get features
get duration
get number jobs
get output stats
get input stats
pig stats
start
stop
is initialized
get job client
get job control compiler
set return code
add job stats
add job stats for native
display
map m r oper to job
set error message
set error code
set backend exception
get pig context
get number successful jobs
get number failed jobs
context
reporter
get instance
set context
pig status reporter
get counter
get counter
progress
set status
generator frame
generator panel
file field
format field
number field
file label
format label
number label
generate button
out
formats
random
stream generator
add widgets
action performed
create and show g u i
main
self
m timers
get perf timer factory
get timer
dump timers
dump timers
performance timer factory
m state
m nanosecs
m started at
m starts
m name
start
stop
print
performance timer
configuration
cluster
exists
update
copy from local file
copy from local file
copy from local file
copy from local file
copy from local file
copy from local file
list status
delete
same size
original text pig script
args
arg files
alias overrides
pig
cluster
log
exec cluster
pig test
pig test
pig test
pig test
pig test
pig test
pig test
pig test
get cluster
register script
run script
get alias
get alias
override
unoverride
assert output
assert output
assert output
assert output
assert output
assert equals
read file
read file
main
alias override
grunt parser
process pig
override
save last store alias
pig server
pig server
register script
dat file
default block size
total
max rand
cluster
count
pig
file name
tmp file 1
set up
tear down
one time tear down
test large file
test order
test distinct
cluster
my pig
set up before class
tear down after class
set up
tear down
test multi query jira pig 1 4 3 8
test multi query jira pig 1 2 5 2
test multi query jira pig 1 1 6 9
test multi query jira pig 1 1 7 1
test multi query jira pig 1 1 5 7
test multi query jira pig 1 0 6 8
test multi query jira pig 1 1 0 8
test multi query jira pig 1 1 1 4
test multi query jira pig 1 1 1 3
test multi query jira pig 1 0 6 0 2
test multi query jira pig 9 2 0 2
test multi query jira pig 9 2 0 3
test multi query jira pig 9 7 6
test multi query jira pig 9 7 6 2
test multi query jira pig 9 7 6 3
test multi query jira pig 9 7 6 4
test multi query jira pig 9 7 6 5
test multi query jira pig 9 7 6 6
test multi query jira pig 9 8 3 2
delete output files
new default bag
new default bag
new sorted bag
new distinct bag
non default bag factory
test datum
test tuple
test nest tuple
test read write
test read write internal
test tuple to string
test tuple hash code
test tuple equals
test tuple compare to
test multi field tuple compare to
test byte array to string
test byte array hash code
test byte array equals
test byte array compare to
test integer conversion err
test integer conversion err 1
test tuple conversion err
test tuple conversion err 1
test byte array append
test map conversion err
test map conversion
test determine field schema err
give me one of each
init string
pig
test local 2
test union 1
test union 1 with nulls
test union 2
test union 2 with nulls
test pig 8 0 0 distinct
test pig 8 0 0 sort
test operator local
test join 1
verify union
gen data set file
input file
i n p u t f i l e 2
i n p u t f i l e 3
i n p u t f i l e 4
pig server
cluster
test accumulator
set up
one time tear down
create files
tear down
test accum basic
test accum with negative
test accum with add
test accum with minus
test accum with mod
test accum with divide
test accum with and
test accum with or
test accum with regexp
test accum with is null
test accum with distinct
test accum with sort
test accum with buildin avg
test accum with buildin
test accum with multi buildin
test accum count star
test accumulator off
test accum with map
log
cluster
dat file
gz file
set up
tear down
one time tear down
test compressed 1
test compressed 2
set up
tear down
test integer gt
test integer lt
test integer eq
test integer and null values
test long gt
test long lt
test long eq
test long and null values
test float gt
test float lt
test float eq
test float and null values
test double gt
test double lt
test double eq
test double and null values
test string gt
test string lt
test string eq
test string and null values
test data byte array gt
test data byte array lt
test data byte array eq
test data byte array and null values
check null values
test spec ctor class name
test spec ctor class name no args
test spec ctor class name with args
test ctor class name args
pig
cluster
std out redirected file
file separator
set up
tear down
one time tear down
verify string contained
create fake jar file
register new resource
test register jar file not present
test register jar local dir
test register jar from resources
test register jar resource in jar
test describe load
test describe filter
test describe distinct
test describe sort
test describe limit
test describe foreach
test describe foreach fail
test describe foreach no schema
test describe cogroup
test describe cross
test describe join
test describe union
test describe complex
test param substitution
test pig properties
test pig temp dir
pig
tmp file
tmpfilepath
datalen
cluster
set up
tear down
one time tear down
verify
test sample none
test sample all
test sample some
test union 1
test union 2
test split with inner plan 1
test split with inner plan 2
test distinct 1
test sort 1
test filter 1
test filter 2
test cross 1
test cross 2
test c o group by atom 1
test c o group by tuple 1
test for each generate 1
r
lt
rt
op
set up
test matches
test doesnt match
log
a
max range
r
pc
generate
aliases
logical op table
alias op
file name map
set up
test complex foreach
test sort
test distinct
test cogroup
test arithmetic
test comparison
test bin cond
test generate
test union
test split
test is null
test limit
test err limit
test err filter
test err sort
test err null
test sort info asc
test sort info asc desc
test sort info no order by 1
test sort info no order by 2
test sort info order by limit
test sort info multiple store
test sort info no order by schema
get sort info
build physical plan
build plan
build plan
datalen
data
cluster
pig
tmp file
test order by
set up
tear down
one time tear down
verify
test top level order by star no using
test top level order by col 1 no using
test top level order by col 2 no using
test top level order by col 2 1 no using
test top level order by star using
test top level order by col 1 using
test top level order by col 2 using
test top level order by col 2 1 using
test nested order by star no using
test nested order by col 1 no using
test nested order by col 2 no using
test nested order by col 2 1 no using
test nested order by star using
test nested order by col 1 using
test nested order by col 2 using
test nested order by col 2 1 using
test order by group
r
bag
bag default
bag with null
bag with boolean
bag with boolean and null
max
set up
test p o bin cond with integer
test p o bin cond with long
test p o bin cond with float
test p o bin cond with double
test p o bin cond int with null
test p o bin cond long with null
test p o bin cond double with null
get bag
get bag with nulls
log
pc
plan tester
simple echo streaming command
tear down
test query foreach 1
test query foreach 2
test query cogroup 1
test query group all
test query group 2
test query cogroup 2
test query group 3
test query filter no schema
test query split no schema
test query order by no schema
test query limit no schema
test query distinct no schema
test query streaming no schema
test query streaming no schema 1
test query foreach 3
test query foreach 4
test foreach 5
test query cross no schema
test query union no schema
test query f r join no schema
test query join no schema
test query filter with schema
test query split with schema
test query order by with schema
test query limit with schema
test query distinct with schema
test query streaming with schema
test query streaming with schema 1
test query implicit join with schema
test query cross with schema
test query union with schema
test query f r join with schema
test query join with schema
test query cross with mixed schema
test query union with mixed schema
test query f r join with mixed schema
test query join with mixed schema
cluster
pig server
m tf
m bf
set up
one time tear down
test scalar aliases batch nobatch
test use scalar multiple times
test scalar with no schema
test scalar with two branches
test filtered scalar dollar proj
test scalar with no schema dollar proj
test scalar aliases join clause
test scalar aliases filter clause
test scalar aliases split clause
test scalar err multiple rows in input
test scalar aliases grammar negative
test scalar aliases limit
cluster
pig server
pc
one time tear down
set up
test distinct optimization 1
test distinct optimization 2
test distinct optimization 3
test distinct optimization 4
test distinct optimization 5
test distinct optimization 6
test distinct optimization 7
test distinct optimization 8
test distinct optimization 9
test sort optimization 1
test sort optimization 2
test sort optimization 3
test sort optimization 4
test sort optimization 5
test sort optimization 6
test sort optimization 7
test sort optimization 8
test nested distinct end to end 1
test nested distinct end to end 2
test nested sort end to end 1
test nested sort end to end 2
test nested sort end to end 3
test nested sort multi query end to end 1
set up
tear down
test integer ne
test integer eq
test integer and null values
test long ne
test long eq
test long and null values
test float ne
test float eq
test float and null values
test double ne
test double eq
test double and null values
test string ne
test string eq
test string and null values
test data byte array ne
test data byte array eq
test tuple eq
test tuple ne
test map eq
test map ne
test data byte array and null values
check null values
there was a timeout
test timeout
test timeout with default
test custom error handler
test no timeout
main
plan
join
set up
test multi node
test single node match
test two node match
simple echo streaming command
pc
plan tester
test query foreach 1
test query foreach 2
test query foreach 3
test query cogroup 1
test query group all
test query group 2
test query cogroup 2
test query group 3
test query filter no schema
test query split no schema
test query order by no schema
test query limit no schema
test query distinct no schema
test query streaming no schema
test query streaming no schema 1
test query foreach 4
test foreach 5
test query cross no schema
test query union no schema
test query f r join no schema
test query join no schema
test query filter with schema
test query split with schema
test query order by with schema
test query limit with schema
test query distinct with schema
test query streaming with schema
test query streaming with schema 1
test query implicit join with schema
test query cross with schema
test query union with schema
test query f r join schema
test query join with schema
test query cross with mixed schema
test query union with mixed schema
test query f r join with mixed schema
test query join with mixed schema
test query filter with star no schema
test query order by star no schema
test query group by star no schema
test query f r join on star no schema
test query join on star no schema
test query filter star with schema
test query split with star schema
test query order by star with schema
test query group by star with schema
test query f r join on star with schema
test query join on star with schema
test query foreach generate star no schema
test query foreach generate count star no schema
test query foreach generate star no schema 1
test query foreach generate star no schema 2
test query foreach generate star with schema
test query foreach generate count star with schema
test query foreach generate star with schema 1
test query foreach generate star with schema 2
i n p u t f i l e 1
i n p u t f i l e 2
i n p u t f i l e 3
i n p u t f i l e 4
i n p u t f i l e 5
empty file
data with null keys
cluster
set up
tear down
one time tear down
test compilation
test failure 1
test failure 2
test simple
test 3 way
test multi splits
test cogrp on multi keys
test empty delta file
test data with null keys
file base location
max size
pc
plan tester
setup
tear down
compare with golden file
print limit graph
test o p limit 1 optimizer
test o p limit 2 optimizer
test o p limit 3 optimizer
test o p limit 4 optimizer
test o p limit 5 optimizer
test o p limit 6 optimizer
test o p limit 7 optimizer
test o p limit 8 optimizer
test o p limit 9 optimizer
test o p limit 1 0 optimizer
test op limit optimizer check
test err op limit optimizer
test o p limit 1 1 optimizer
migrate and optimize plan
migrate plan
test bytes written j i r a 1 0 2 7
test pig stats alias
delete directory
get logical plan
get m r plan
get alias
st
inp d b
cluster
pc
proj
pig
pcount
input file name
output file name
dummy store class name
fail udf name
map max attempts
set up
tear down
store and copy locally
one time tear down
store
test validation
test validation failure
test store
set up input file on cluster
to delimited string
test store complex data
test store complex data with null
test bin storage get schema
randomize bytes
test store remote rel
test store remote abs
test store remote rel scheme
test store remote abs scheme
test store remote abs auth
test store remote normalize
test set store schema
test cleanup on failure
test cleanup on failure multi store
test success file creation 1
test success file creation 2
cleanup files
check store path
check store path
log
tuple factory
bag factory
ps
get tuple field schema
get bag field schema
get long field schema
test integer
test long
test float
test double
test string
test map string value type
test map integer value type
test map long value type
test map float value type
test map double value type
test tuple
test bag
test empty bag
log
exec type
cluster
pig server
set up
tear down
one time tear down
log
cluster
conf
hbase cluster
zoo keeper cluster
pig
num regionservers
t e s t t a b l e 1
t e s t t a b l e 2
columnfamily
testcolumn a
testcolumn b
testcolumn c
family
test row count
set up
one time tear down
h base cluster setup
tear down
test load from h base
test backwards compatibility
test load from h base with row key
test load with parameters 1
test load with parameters 2
test load with parameters 3
test h base binary converter
test store to h base 1
test store to h base 2
prepare table
delete table
r
max tuples
test user func arity
test user func arity with nulls
user func arity
test u d f compare
test u d f compare with nulls
udf compare
test algebraic a v g
test algebraic a v g with nulls
algebraic a v g
input file
cluster
one time setup
tear down after class
test group all with parallel
test group const with parallel
test group non const with parallel
cluster
pig server
tf
simple echo streaming command
setup
tear down
one time tear down
setup expected results
test simple map side streaming
test simple map side streaming with output schema
test simple reduce side streaming after flatten
test simple ordered reduce side streaming after flatten
test input ship specs
test input ship specs with u d f define
test input cache specs
test output ship specs
test output ship specs with u d f define
test input output specs
test simple map side streaming with unix pipes
test negative load store optimization
cluster
one time tear down
test bzip in pig
test bzip in pig 2
test record delims
test empty bzip in pig
test empty bzip
test block header ending at split not byte aligned
test block header ending with c r
test block header ending at split over counting
test count
test bzip store in multi query
test bzip store in multi query 2
cogroup
partial flatten
simple generate
r
bf
tf
set up
test join
test partial join
test simple generate
cluster
i n p f i l e 2 n u m s
check instance store func
set up
tear down
one time setup
one time tear down
test backend store communication
test schema equal 1
test schema equal with null schema 1
test normal nested merge 1
test merge null schemas 1
test merge null schemas 2
test merge different size 1
test merge different size 2
test merge mismatch type 1
test merge mismatch type 2
test merge mismatch type 3
test merge different size and type mismatch 1
test schema equal two level access
test char array 2 numeric
test schema serialization
sb
current tab count
type graph printer
print tabs
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
append op
print to string
r
ce
set up
tear down
test get next integer
test get next long
test get next double
test get next float
test get next string
test get next data byte array
test get next map
test get next boolean
test get next tuple
test get next data bag
log
pig
set up
test big group all
test big group all with null
big group all
test store function
test store function no nulls
test store function with nulls
store function
test qualified functions
test qualified functions with nulls
test defined functions
test defined functions no nulls
test defined functions with nulls
defined functions
gen data set file 1
r
max
dummy tuple
dummy map
dummy bag
test integer to other
test long to other
test float to other
test double to other
test string to other
test byte array to other
construct plan
test byte array to other no cast
test tuple to other
test bag to other
test map to other
test null to other
test value types changed
pc
plan tester
simple echo streaming command
set up
test expression type checking 1
test expression type checking fail 1
test expression type checking 2
test expression type checking 3
test expression type checking 4
test expression type checking fail 4
test expression type checking 5
test expression type checking 6
test expression type checking 7
test expression type checking 8
test expression type checking 9
test arithmetic op cast insert 1
test arithmetic op cast insert 2
test mod cast insert 1
test regex type checking 1
test regex type checking 2
test regex type checking 3
test union casting insert 1
test union casting insert 2
test distinct 1
test filter with inner plan 1
test filter with inner plan 2
test filter with inner plan
test filter with inner plan 3
test sort with inner plan 1
test sort with inner plan 2
test sort with inner plan 3
test split with inner plan 1
test split with inner plan 2
test c o group with inner plan 1 group by tuple 1
test c o group with inner plan 1 group by atom 1
test c o group with inner plan 1 group by incompatible atom 1
test for each generate 1
test for each generate 2
test for each generate 4
test cross 1
test lineage 1
test lineage 1 no schema
test lineage 2
test group lineage
test group lineage no schema
test group lineage 2
test group lineage 2 no schema
test group lineage star
test group lineage star no schema
test cogroup lineage
test cogroup map lookup lineage
test cogroup star lineage
test cogroup star lineage fail
test cogroup star lineage 1
test cogroup star lineage no schema fail
test cogroup multi column project lineage
test cogroup project star lineage
test cogroup project star lineage no schema
test cogroup project star lineage mix schema
test cogroup lineage fail
test cogroup lineage 2 no schema
test union lineage
test union lineage fail
test union lineage no schema
test union lineage no schema fail
test union lineage different schema
test union lineage different schema fail
test union lineage mix schema
test union lineage mix schema fail
test filter lineage
test filter lineage no schema
test filter lineage 1
test filter lineage 1 no schema
test cogroup filter lineage
test cogroup filter lineage no schema
test split lineage
test split lineage no schema
test split lineage 1
test split lineage 1 no schema
test cogroup split lineage
test cogroup split lineage no schema
test distinct lineage
test distinct lineage no schema
test cogroup distinct lineage
test cogroup distinct lineage no schema
test sort lineage
test sort lineage no schema
test cogroup sort lineage
test cogroup sort lineage no schema
test cogroup sort star lineage
test cogroup sort star lineage no schema
test cross lineage
test cross lineage no schema
test cross lineage no schema fail
test cross lineage mix schema
test cross lineage mix schema fail
test join lineage
test join lineage no schema
test join lineage no schema fail
test join lineage mix schema
test join lineage mix schema fail
test limit lineage
test limit lineage no schema
test cogroup limit lineage
test cogroup limit lineage no schema
test cogroup top k lineage
test cogroup top k lineage no schema
test streaming lineage 1
test streaming lineage 2
test cogroup streaming lineage
test cogroup streaming lineage no schema
test map lookup lineage
test map lookup lineage no schema
test map lookup lineage 2
test map lookup lineage 3
test twolevel map lookup lineage
run type checking validator
check loader in casts
test bincond
test bin cond for outer join
test map lookup cast
check for each casting
test lineage multiple loader 1
test lineage multiple loader 2
test lineage multiple loader 3
test lineage filter with tuple
test lineage expression casting
test bag dereference
test
set location
pig server
set up
test pinned join option
test not pinned jin option
test group options
get op by alias
cluster
input file
output file
pig file
set up before class
tear down after class
set up
test error log file
test error log file 2
simple test
scripts in dfs test
order by test
simple multi query test
simple multi query test 2
m q dep job failed test
simple negative test
simple negative test 2
simple negative test 3
nagetive test
test is temp file
test counter name
test long counter name
test register external jar
class loader test
delete all
test tuple write read 1
test tuple write read int diff sizes
test tuple write read byte arr string diff sizes
test tuple write read bag diff sizes
create bag
test tuple write read diff sizes
create tuple with many cols
test tuple write read map diff sizes
create map
test tuple sedes
cluster
pig server
m tf
m bf
set up
one time tear down
test null join
input file name
test pig split
create input
tear down
notest long eval spec
test schema with split
test long eval spec
sp
exp bag
cluster
pc
set up
tear down
one time tear down
cast to d b a
test get next tuple
test get next null input
test schema merge with bag
r
set up
test ordering
test regex determination
pattern 
regex group count
exec
r
test cogroup 2 inputs
test cogroup 1 input
fr input file
s k e w i n p u t f i l e 1
s k e w i n p u t f i l e 2
s k e w i n p u t f i l e 5
pig server
cluster
tmp file
test join smoke
set up
setup f r join
setup skew join
one time tear down
tear down
tear down skew join
test f r join
test skewed join with group
test skewed join outer
pc
plan tester
plan
load 1
load 2
filter
join
store
prep
test filter rule
test filter rule with and
test filter rule with 2 and
test filter rule with 2 and 2
test filter u d f negative
migrate and optimize plan
migrate plan
test bag format
log
pc
plan tester
simple echo streaming command
tear down
test query foreach 1
test query foreach 2
test query cogroup 1
test query group all
test query group 2
test query cogroup 2
test query group 3
test query filter no schema
test query split no schema
test query order by no schema
test query limit no schema
test query distinct no schema
test query streaming no schema
test query streaming no schema 1
test query foreach 3
test query foreach 4
test foreach 5
test query cross no schema
test query union no schema
test query f r join no schema
test query join no schema
test query filter with schema
test query split with schema
test query order by with schema
test query limit with schema
test query distinct with schema
test query streaming with schema
test query streaming with schema 1
test query implicit join with schema
test query cross with schema
test query union with schema
test query f r join with schema
test query join with schema
test query cross with mixed schema
test query union with mixed schema
test query f r join with mixed schema
test query join with mixed schema
test query filter with star no schema
test query order by star no schema
test query group by star no schema
test query f r join on star no schema
test query join on star no schema
test query filter star with schema
test query split with star schema
test query order by star with schema
test query group by star with schema
test query f r join on star with schema
test query join on star with schema
test query foreach generate star no schema
test query foreach generate count star no schema
test query foreach generate star no schema 1
test query foreach generate star no schema 2
test query foreach generate star with schema
test query foreach generate count star with schema
test query foreach generate star with schema 1
test query foreach generate star with schema 2
r
map
test map look up
input file
i n p u t f i l e 2
pig server
cluster
test merge join
set up
one time tear down
tear down
test recursive file listing
test merge join simplest
test merge join on multi fields
test merge join with expr
test merge join out with schema
test merge join out with filters
test merge join out with projects
test merge join out pipeline
test merge join with nulls
test merge join with m r boundary later
test merge join 3 way
test merge join failure 1
test merge join failure 2
test empty right file
test parallelism
test indexer
test expression
test expression fail
test merge join sch 1
test merge join sch 2
test merge join with comma separated file paths
test merge join empty index
pig server
cluster
set up
tear down
one time tear down
test implicit split
test implicit split in co group
test implicit split in co group 2
data
off
fake f s output stream
write
input
r
max value
max samples
set up
test p o distict with int
test p o distict with null values
test p o distict with int and null values
test p o distict with int null values
test p o distict with null int values
test p o distict arity with null values
confirm distinct
pig server
cluster
log file
set up
reset log
check log file message
tear down
one time tear down
test implicit split uncompressed
test implicit split in co group uncompressed
test implicit split
test implicit split in co group
cluster
pig server
set up
one time tear down
test single tuple bag acess
test non spillable data bag
test bag constant access
test bag constant access failure
test bag constant flatten 1
test bag constant flatten 2
test bag store load
inputs
r
set up
test cross
pig server
m tf
m bf
f 1
cluster
set up
one time tear down
set up
check and cleanup
test finish in map m r
test finish in reduce m r
test finish in map loc
test finish in reduce loc
cluster
pig
test map reduce 2
one time tear down
test union 1
test union 1 with nulls
test union 2
test union 2 with nulls
verify union
gen data set file
cluster
pig
set up
tear down
one time tear down
simple test
r
lt
rt
op
set up
test operator
pc
log
plan tester
simple echo streaming command
tear down
test query foreach filter swap
test query foreach filter swap 1
test negative query foreach 1
test query sort filter swap
test query split filter insert between
test query f r join filter push before
test query cogroup filter push before
test query f r join filter push before negative
test query cogroup filter push before negative
test query cogroup trim above negative
test query cogroup trim above negative 1
test query replace filter
test query reemove filter and reconnect
my pig
set up
tear down
test multi query with two stores
test empty execute
test multi query with two stores 2
test multi query with two stores 2 execs
test multi query with three stores
test multi query with three stores 2
test multi query with two loads
test multi query with two loads 2
test multi query with no store
test multi query with no store 2
test multi query with explain
test multi query with dump
test multi query with describe
test multi query with illustrate
test store order
show plan operators
check logical plan
check physical plan
execute plan
delete output files
delete dir
is directory
exec
output schema
pig server
m tf
set up
create file
test function inside function
test join
test driver method
test map lookup
test bag function with flattening
test sort with u d f
test distinct
test sort distinct
test nested plan
test nested plan with expression assignment
test limit
test complex data
test bin storage determine schema
test project bag
test bin storage determine schema 2
test cogroup with input from group
test utf 8 dump
test map u d f
test map u d f fail
test load ctor args
test nested plan for cloning
test arithmetic cloning
test expression re use
test identity
file base location
max size
pc
plan tester
simple echo streaming command
tear down
test error empty input
test error non filter input
test filter load
test filter streaming
test filter sort
test filter constant condition sort
test filter u d f sort
test filter distinct
test filter constant condition distinct
test filter u d f distinct
test filter foreach
test filter foreach added field
test filter foreach cast
test filter cast foreach
test filter constant condition foreach
test filter u d f foreach
test filter foreach flatten
test filter filter
test filter split output
test filter limit
test filter union
test filter constant condition union
test filter u d f union
test filter cross
test filter cross 1
test filter cross 2
test filter constant condition cross
test filter u d f cross
test filter cogroup
test filter constant condition cogroup
test filter u d f cogroup
test filter cogroup outer
test filter constant condition cogroup outer
test filter u d f cogroup outer
test filter group by
test filter constant condition group by
test filter u d f group by
test filter group by outer
test filter constant condition group by outer
test filter u d f group by outer
test filter f r join
test filter f r join 1
test filter constant condition f r join
test filter u d f f r join
test filter inner join
test filter inner join 1
test filter constant condition inner join
test filter u d f inner join
test filter nested for each
test out join
test full out join
lr
t
db
cluster
set up
one time tear down
set up 1
tear down
test get next tuple 1
set up 2
test get next tuple 2
test multi query jira pig 1 1 9 4
cluster
basedir
log
one time setup
one time tear down
test define
test bag schema
test bag schema fail
test bag constant
test bag constant with schema
test bag constant in foreach block
test bag constant with schema in foreach block
test parsing as in foreach block
test parsing as in foreach with out block
test parsing word with as in foreach block
test parsing word with as in foreach with out block
test parsing word with as in foreach with out block 2
test parsing generate in foreach block
test parsing generate in foreach with out block
test parsing as generate in foreach block
test parsing as generate in foreach with out block
test run statment
test exec statment
test run statment nested
test exec statment nested
test explain empty
test explain script
test explain script 2
test explain brief
test explain dot
test explain out
test partial execution
test file cmds
test c d
test dump
test illustrate
test keep going
test keep goig failed
test invalid param
test stop on failure
test fs command
test shell command
test set priority
test set with quotes
test register with quotes
test register without quotes
test register scripts
compare
r
lt
rt
op
set up
test operator
tf
comparator
old comparator
list
prototype
baos 1
baos 2
dos 1
dos 2
tuple number
times
seed
ab
set up
test compare equals
test compare float
test compare int
test compare double
test compare byte
test compare boolean
test compare byte array
test compare char array
append chars
compare inner tuples
create large tuple
test compare data bag
create large bag
test compare map
test compare differt types
test compare different sizes
test random tuples
test sort order
get random tuple
compare helper
random string
main
pc
lp tester
set up
test simple mixed
test no part filter
test only part filter 1
test only part filter 2
test only part filter 3
test mixed 1
test mixed 2
test mixed 3
test mixed 4
test mixed 5
test mixed 6
test mixed arith
test neg p col condition with non p col
test neg p col in wrong places
test col name mapping 1
test col name mapping 2
test col name mapping 3
test col name mapping 4
test col name mapping 5
test
negative test
m next key
scope
node id gen
max optimization iterations
test add remove
test insert between
test insert between negative
test linear graph
test d a g
test optimizer different nodes
test optimizer different edges
test optimizer matches
test optimizer matches any
test optimizer matches part
test optimizer optional matches
test optimizer optional missing
test check
test replace
test replace no connections
test multi input pattern
test isomorphic multi input pattern
test multi input multi output pattern
test multi output pattern
test negative multi output pattern
test negative multi output pattern 1
test multiple multi input pattern in disconnected graph
test multiple multi input pattern
test single multi input pattern
test diamond pattern
test diamond with edge pattern
test complex input pattern
test negative complex input pattern
test swap roots in disconnected graph
test simple swap
test simple swap 2
test simple swap 3
test simple swap 4
test negative simple swap
test negative simple swap 1
testpush before
testpush before 2
test negative push before
test negative push before 2
testpush after
testpush after 1
test negative push after
test negative push after 2
test push before 2
r
log
pig context
aliases
logical op table
alias op
file name map
test split
test split nulls
build physical plan
build plan
build plan
refine logical plan
init
r
lt
rt
op
set up
test operator
log
exec type
cluster
pig server
set up
tear down
one time tear down
test loading nonexistent file
test remote server list
test remote server list 2
fe
t
db
proj d b
set up
tear down
test get next tuple
init string
pig
null flags
test for each nested plan local
test inner order by
test inner limit
gen data set file 1
gen data set file one group
r
lt
rt
bop
uop
dummy
set up
setup and
setup or
setup not
test and null
test or null
test and first false
test and second false
test and both false
test and true
test or first false
test or second false
test or both false
test or true
test not true
test not false
test not null
test register dash
test double register short
test double register long
test register
test parse no args
test parse no dash
test parse long short no leftover
test parse long short leftover 1
test parse long short leftover 2
test parse long short leftover 3
test parse value not accepted provided 1
test parse value not accepted provided 2
test parse value required not provided 1
test parse value required not provided 2
test parse value str for int
test parse unknown short
test parse unknown long
set up
tear down
test
test operator
test plan edge insert
test plan edge insert first index bad
test operator plan
test disconnect and remove
test remove negative
test disconnect negative
test dependency order walker linear
test dependency order walker tree
test dependency order walker graph
test depth first walker linear
test depth first walker tree
test depth first walker graph
test reverse dependency order walker linear
test reverse dependency order walker tree
test reverse dependency order walker graph
test logical plan visitor
test binary operator order
test expression plan visitor
test expression equality
test relational equality
test load equality different func spec ctor args
test load equality different num func spec cstor args
test load equality different function names
test load equality different file name
test relational equality different schema
test relational equality null schemas
test relational equality one null one not null schema
test filter different predicates
test join different join types
test join different inner
test join different num inputs
test join different join keys
test join different num join keys
test relational same op different preds
test replace 1
test replace 2
test replace 3
test replace 4
test replace 5
test replace 6
test remove 1
test remove 2
test remove 3
test remove 4
test remove 5
test remove 6
test insert between 1
lp
changed plan
set up
test all same visitor
test all expression visitor
test schema patcher
test projection patcher
cluster
pc
pc m r
max size
seed
r
plan tester
plan tester m r
generate
set up
tear down
test run 1
test run 2
test spl 1
test spl 2
test spl 3
test sim 1
test sim 2
test sim 3
int test sim 4
test sim 5
test sim 6
test sim 7
test sim 8
test sim 9
test sort u d f 1
test distinct 1
test limit
test m r compiler err
test m r compiler err 1
test num reducers in limit
test num reducers in limit with parallel
test u d f in join
test merge join
test merge join with indexable load func
test cast func shipped
test sorted distinct in foreach
run
cluster
pig server
m tf
m bf
set up
one time tear down
test udf input order
test u d fwith star input
test bin storage byte array casts simple
test bin storage byte array casts complex bag
test bin storage byte array casts complex tuple
test pig storage with ctrl chars
test limited sort with dump
test limit after sort
test limit after sort desc
test empty sort
test limit p o package annotator
test nested desc sort
test custom partitioner parse joins
test custom partitioner groups
test custom partitioner cross
test describe nested alias
test bin storage comma seperated path
test empty bag iterator
test push up filter scalar
test duplicate reference inner plan
test bin cond schema
test duplicate inner alias
test dereference inner plan
test l o generate schema
test merge schema error message
test for each dup column
test bag dereference in middle
test for each same origin column
loop count
pig
null flags
set up
test group count with multiple fields
test simple count
test group count
test group reorder count
test group unique column count
test group duplicate column count
generate input
cluster
pig
null flags
test for each nested plan
one time tear down
test inner order by
test inner order by star with schema
test multi col in alias
test algebric func without group by
test inner distinct
gen data set file 1
r
t
t random
t random and null
res
proj
set up
tear down
test get next
test get next tuple
test get next multiple projections
test get next tuple multiple projections
test get next with null
test get next tuple with null
test get next multiple projections with null
test get next tuple multiple projections with null
test missing cols 1
test missing cols 2
test missing cols 3
test null tuple cols
data
off
fake f s input stream
get pos
seek
read
cluster
pig server
m tf
set up
one time tear down
test checkin 1
test checkin 2
pig
pig context
tmp file
cluster
test split store
set up
tear down
one time tear down
test 1
test 2
test 3
test 4
test 5
test 6
test 7
test 8
test 9
pig storage no def ctor
cluster
empty dir
input file
output file
pig file
set up before class
tear down after class
test skewed join
test merge join
test f r join
test regular join
test right outer join
test left outer join
tf
pig server
simple echo streaming command
set up
tear down
setup expected results
test simple map side streaming
test simple map side streaming with output schema
test simple reduce side streaming after flatten
test simple ordered reduce side streaming after flatten
test simple map side streaming with unix pipes
test join two streaming relations
test local negative load store optimization
test negative load store optimization
pass
fail
t
inp
proj fil
null flags
set up
set up proj fil
tear down
test get next tuple
get exp count
test simple filter
test and filter
main
cluster
loop count
file name
tmp file 1
tmp file 2
pig
one time tear down
test single store
test multiple store
test store with multiple m r jobs
set up
ps
r
max
test bytes to integer
test bytes to float
test bytes to double
test bytes to long
test bytes to char
test bytes to tuple
test bytes to bag
test bytes to map
test integer to bytes
test long to bytes
test float to bytes
test double to bytes
test char array to bytes
test tuple to bytes
test bag to bytes
test map to bytes
test bytes to bag with conversion
test bytes to tuple with conversion
test bytes to complex type misc
test overflow
cluster
set up before class
tear down after class
test null match
test tuple null match
test left null match
test tuple left null match
cluster
input dir
input file
file merge threshold
min file merge threshold
concat i n p u t d i r
log file
set up before class
tear down after class
test concatenate job for scalar
test concatenate job for scalar 2
test concatenate job for scalar 3
test concatenate job for f r join
test too many reducers
test unknown num maps
test unknown num maps 2
tf 
bf 
test string invoker
test no arg invoker
test long invoker
test int invoker
test array conversion
test double invoker
test float invoker
concat strings
concat string array
simple static function
avg
avg
new simple bag
test speed
plan
pc
migrate plan
setup
tear down
test simple
test complex
test duplicate inputs
test negative 1
test negative 2
test join input order
get for each operator count
get output expr count
get for each operator
get operator
pc
one time tear down
test optimizer fired
test optimizer not fired
test end to end
test poisson sample optimizer
test order by u d f set
cluster
my pig
set up before class
tear down after class
set up
tear down
test multi query jira pig 1 4 3 8
test multi query jira pig 1 0 6 0
test multi query jira pig 9 2 0
test multi query jira pig 9 2 0 1
test multi query with demo case
test multi query with single map reduce splittee
test multi query phase 3 base case
test multi query jira pig 9 8 3
test multi query phase 3 without combiner
test multi query phase 3 with mixed combiner
test multi query phase 3 with different map data types
test multi query phase 3 streaming in reducer
test multi query with pig mix l 1 2
test multi query with co group
test multi query with f j
test multi query with explicit split and side files
test multi query with explicit split and order by and side files
test multi query with intermediate stores
test multi query with implicit split and side files
test multi query with two loads and two stores
test multi query with split in reduce
test multi query with split in reduce and reduce splitee
test multi query with split in reduce and reduce splitees
test multi query with split in reduce and reduce splitees and more
test multi query with split in map and reduce splitees
test multi query with two stores
test multi query with three stores
test multi query with two loads
test store order
test unnecessary store removal
test unnecessary store removal collapse split
test empty filter removal
test multi query with describe
test multi query with illustrate
test multi query with explain
test multi query with dump
test empty execute
test load store loop
test multi query with no store 2
show plan operators
check logical plan
check physical plan
check physical plan
check m r plan
delete output files
dummy double
dummy float
dummy long
dummy integer
max double
min double
max float
min float
max long
min long
max integer
min integer
cluster
pig
set up
one time tear down
new operator key
test cast
test char array 2 float and double script
test char array to int and long script
signature
get partition keys
get schema
get statistics
set partition filter
set u d f context signature
get u d f context signature
cluster
my pig
set up
tear down
one time tear down
test batch aliases
delete output files
cluster
pig context
rand
max
a
b
set up
one time tear down
write data
test filter
test foreach
test join
test cogroup multiple cols
test cogroup
test group
test union
loop count
tmp file
server
context
set up
delete directory
test one succ store
test two succ store
test one fail store
test two fail store
test one succ one fail store
jar file name
exp msg prefix
input file
stopword file
cluster
pig server
one time setup
set up
one time tear down
test native m r job simple
test native m r job simple failure
test native m r job multi store on pred
test native m r job multi query opt
test native m r job type cast inserter
pig server
cluster
tmp file
tf
test filter u d f
set up
tear down
one time tear down
create file
test filter u d f
test filter u d fusing define
test filter u d fusing define 2
string substr 
substr 
test string substr
test index of
test last index of
test replace
test trim
test split
set up
tear down
test integer gt
test integer lt
test integer eq
test integer and null values
test long gt
test long lt
test long eq
test long and null values
test float gt
test float lt
test float eq
test float and null values
test double gt
test double lt
test double eq
test double and null values
test string gt
test string lt
test string eq
test string and null values
test data byte array gt
test data byte array lt
test data byte array eq
test data byte array and null values
check null values
test resource flat schema creation
test resource flat schema creation 2
test resource flat schema creation with sort info
test to pig schema with two level access
check two level access
test to pig schema with invalid schema
test to pig schema with invalid schema 2
test resource schema with invalid pig schema
test resource schema with invalid pig schema 2
pc
lp tester
setup
tear down
test simple mixed
test no part filter
test only part filter 1
test only part filter 2
test only part filter 3
test mixed 1
test mixed 2
test mixed 3
test mixed 4
test mixed 5
test mixed 6
test mixed arith
test neg p col condition with non p col
test neg p col in wrong places
test col name mapping 1
migrate and optimize plan
test col name mapping 2
test col name mapping 3
test col name mapping 4
test col name mapping 5
test
negative test
migrate plan
test filter push down
test tuple format
test empty tuple size
test empty bag size
test tuple size with string
test tuple size with byte arrays
test tuple size with doubles
test tuple size with floats
test tuple size with longs
test tuple size with booleans
input file
i n p u t f i l e 2
pig server
cluster
tmp file
test f r join
set up
one time tear down
tear down
test sort f r join
test distinct f r join
test u d f f r j
test f r join out 1
test f r join out 2
test f r join out 3
test f r join out 4
test f r join out 5
test f r join out 6
test f r join out 7
test f r join out 8
test f r join out 9
test f r join sch 1
test f r join sch 2
test f r join sch 3
test f r join sch 4
test f r join sch 5
test f r join sch 6
cluster
set up
one time tear down
test u d f context
r
max tuples
test p o sort asc string
test p o sort asc string with null
po sort asc string
test p o sort desc string
test p o sort desc string with nulls
po sort desc string
test p o sort asc
test p o sort asc with nulls
po sort asc int
test p o sort desc int
test p o sort desc int with nulls
po sort desc int
test p o sort mix asc desc 1
test p o sort mix asc desc 1 with null
test p o sort mix asc desc 2
test p o sort mix asc desc 2 null
test p o sort u d f
test p o sort u d f with null
po sort u d f with null
pig server
cluster
set up
tear down
one time tear down
test implicit split
test implicit split in co group
test implicit split in co group 2
log
pig i stream
pig o stream
pig ex result stream
basedir
test param sub preproc
test cmdline param
test file param
test shell command
test pig param not resolved
test undefined param
test substitution within value
test substitution within shell command
test cmdline param priorto declare
test cmdname as param declare
test multiple cmdline param
test file params from multiple files
test same param in multiple files
test multiple params from single file
test empty comment linein configfile
test invalid linein configfile
test valid linesin configfile
test cmdline file combo
test cmdline file combo duplicate
test cmdline file declare combo
test cmdline file declare combo duplicates
test multiple declare scope
test default param
test cmdline file declare default combo duplicates
test multiple paramsin single line
test substitute within literal
test escaping
test cmdline param with inline cmd
test no vars
test complex vals
test comment with param
init string
cluster
pig
test order by 2
test top level order by col 0 a s c no using
test top level order by col 0 d e s c no using
test top levelee order by col 1 a s c no using
test top levelee order by col 1 d e s c no using
test top levelee order by col 0 col 1 no using
test top levelee order by col 0 col 1 d e s c no using
test top levelee order by col 1 col 0 no using
test top levelee order by col 1 col 0 d e s c no using
test top levelee order by col 1 col 0 a s c d e s c no using
test top level order by star no using
test top level order by star d e s c no using
check order
run test
gen data set file 1
gen data set file 2
gen data set file 3
cluster
pig server
set up
one time tear down
test pig storage
test script parser
test query parser
test param substitution
rand
tear down
test default in memory
test default single spill
test default triple spill
test default in mem in file
test default spill during read
test sorted in memory
test sorted single spill
test sorted triple spill
test sorted in mem in file
test sorted spill during read
test sorted first spill during read
test sorted pre merge
test distinct in memory
test distinct single spill
test distinct triple spill
test distinct in mem in file
test distinct spill during read
test distinct pre merge
test default bag factory
test provided bag factory
test non spillable data bag equals 1
test non spillable data bag equals 2
test default data bag equals 1
test default data bag equals 2
test internal cached bag
test internal sorted bag
test internal distinct bag
test data bag iter idempotent
test serialize single tuple bag
process data bag
set up
tear down
test integer gt
test integer lt
test integer eq
test integer and null values
test long gt
test long lt
test long eq
test long and null values
test float gt
test float lt
test float eq
test float and null values
test double gt
test double lt
test double eq
test double and null values
test string gt
test string lt
test string eq
test string and null values
test data byte array gt
test data byte array lt
test data byte array eq
test data byte array and null values
check null values
i n p u t f i l e 1
i n p u t f i l e 2
pig server
cluster
test merge join outer
set up
tear down
one time tear down
test compilation
test failure
test left outer
test right outer
test full outer
cluster
pig server
m tf
m bf
exec types
set up
one time tear down
set up
create input file
delete input file
test join with missing fields in tuples
test join unkown schema
test default join
test join schema
test join schema 2
test left outer join
test right outer join
test full outer join
test multi outer join failure
test non regular outer join failure
test join tuple field key
test join null tuple field key
test literals for join algo specification 1
test literals for join algo specification 2
test literals for join algo specification 5
test literals for join algo specification 3
test literals for join algo specification 4
t fact
epsilon
test find quantiles
test find quantiles 2
get prob vec
get prob vec sum
pig server
tmp file 1
tmp file 2
tmp file 3
tmp file 4
tmp file 5
tmp file 6
tmp file 7
tmp file 8
tmp file 9
tmp file 1 0
tmp file 1 1
log file
simple echo streaming command
set up
tear down
check log file message
empty log file message
test load for each 1
test load for each 2
test load for each 3
test join 1
test join 2
test for each filter
test for each 1
test for each 2
test split 1
test split 2
test foreach no schema 1
test foreach no schema 2
test co group 1
test co group 2
test co group 3
test co group 4
test co group 5
test distinct 1
test stream 1
test bin cond 1
test co group 6
test co group 7
test cross 1
test union 1
test f r join 1
test filter 1
test filter 2
test order by 1
test order by 2
test cogroup 8
test join 3
test load for each 4
test for each u d f
test out join 1
test filter 3
test map key 1
test map key 2
test map key 3
test map key 4
test map key 5
test constant plan
test plain plan
test bin storage 1
test bin storage 2
test project cast key lookup
test relay flatten map
test cross at least one column one input
test complex 1
test co group 8
test user defined schema
test shared schema object
test join 4
test filter 4
test split 3
test order by 3
test cogroup 9
test orderby wrong signature
test union mixed pruning
test union mixed schema pruning
test for each flatten
test fields to read duplicated entry
test split 4
test split 5
test inconsistent pruning
test split output with for each
r
lt
rt
op
set up
test operator
cluster
log
aliases
logical op table
alias op
file name map
pig context
test query 1
test query 2
test query 3
test query 4
test query 5
test query 6
test query 7
test query 1 0
test query 1 1
test query 1 2
test query 1 3
test query 1 4
test query 1 5
test query 1 0 0
test query fail 1
test query fail 2
test query fail 3
test query fail 4
test query fail 5
test query 1 7
test query 1 8
test query 1 9
test query 2 0
test query 2 1
test query 2 2
test query 2 2 fail
test query 2 3
test query 2 3 fail
test query 2 3 fail 2
test query 2 3 fail 3
test query 2 4
test query 2 5
test query 2 6
test query 2 7
test query 2 8
test query 2 9
test query 3 0
test query 3 1
test query 3 2
test query 3 3
test query 3 4
test query 3 5
test query 3 6
test query fail 3 7
test query 3 8
test query 3 9
test query fail 3 9
test query 4 0
test query fail 4 1
test query 4 2
test query 4 3
test query fail 4 3
test query 4 4
test query fail 4 4
test query 5 7
test query 5 8
test query fail 5 8
test query 5 9
test query 6 0
test query 6 1
test query 6 2
test query fail 6 2
test query 6 3
test query fail 6 3
test query 6 4
test query fail 6 4
test query 6 5
test query fail 6 5
test query 6 7
test query 6 8
test query 6 9
test query 7 0
test query fail 6 7
test query fail 6 8
test query 7 1
test query 7 2
test query fail 7 2
test query 7 3
test query 7 4
test query 7 7
test limit with long
test query 7 5
test query 7 6
test query 8 0
test query 8 1
test query fail 8 1
test query 8 2
test query fail 8 2
test query 8 3
test query 8 4
test query 8 5
test query 8 6
test query 8 7
test query 8 8
test query 8 9
test query fail 8 9
test query 9 0
test query fail 9 0
test query 9 1
test query 9 2
test query 9 3
test query fail 9 3
test query 9 4
test query fail 9 4
test query 9 5
test query 9 6
test query 9 7
test query 9 8
test query 9 9
test query 1 0 1
test query 1 0 2
test query 1 0 3
test query 1 0 4
test query 1 0 5
test query 1 0 6
test query 1 0 7
test query 1 0 8
test query 1 0 9
test query 1 1 0 fail
test query 1 1 1
test query 1 1 2
test query 1 1 3
test query 1 1 4
test query 1 1 5
test query 1 1 6
test query 1 1 7
test null cons arith exprs
test null cons bincond 1
test null cons bincond 2
test null cons for each generate
test null cons outer join
test null cons concat size
test filter udf define
test load udf define
test load udf constructor arg define
test store udf define
test store udf constructor arg define
test cast alias
test cast
test reserved words in function names
test tokenize schema
test empty tuple const
test empty map const
test empty bag const
test empty tup const recursive 1
test empty tup const recursive 2
test empty tup const recursive 3
test empty bag const recursive
test random empty const
test limit multiple output
test duplicate schema 1
test duplicate schema 2
test cogroup by star failure 1
test cogroup by star failure 2
test cogroup by incompatible schema failure
test loader signature
print plan
check plan for project star
build plan
build plan
test class
t e s t c l a s s 2
test instantiate 1
test instantiate 2
test instantiate 3
test instantiate 4
test instantiate 5
test parser with escape characters
test define u d f
check parsed const content
prepare temp file
set up
tear down
test integer gt
test integer lt
test integer eq
test integer and null values
test long gt
test long lt
test long eq
test long and null values
test float gt
test float lt
test float eq
test float and null values
test double gt
test double lt
test double eq
test double and null values
test string gt
test string lt
test string eq
test string and null values
test data byte array gt
test data byte array lt
test data byte array eq
test data byte array and null values
check null values
pc
translate plan
migrate plan
set up
test simple plan
test join plan
test multi store
test plan with cast
test plan with greater than
test plan with less than
test foreach plan
test foreach plan 2
test planwith plus
test planwith subtract
test planwith multiply
test planwith divide
test planwith mod
test planwith negative
test planwithis null
test planwithis not null
test planwith bin cond
test planwith user func
test planwith user func 2
test cogroup
test cogroup 2
test cogroup 3
test cogroup 4
test user defined for each schema 1
test user defined for each schema 2
sb
optimize limit plan printer
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
append op
append edges
print to string
plan
pc
migrate plan
test no prune
test prune
test prune with map key
test prune with bag
test add foreach
file base location
max size
log
pc
plan tester
simple echo streaming command
tear down
test error empty input
test error non foreach input
test foreach no flatten
test foreach no successors
test foreach streaming
test foreach distinct
test foreach foreach
test foreach filter
test foreach split output
test foreach limit
test foreach union
test foreach cogroup
test foreach group by
test foreach sort
test foreach flatten added column sort
test foreach u d f sort
test foreach cast sort
test foreach cross
test foreach cross 1
test foreach cross 2
test foreach flatten added column cross
test foreach u d f cross
test foreach cast cross
test foreach f r join
test foreach f r join 1
test foreach f r join 2
test foreach flatten added column f r join
test foreach u d f f r join
test foreach cast f r join
test foreach inner join
test foreach inner join 1
test foreach inner join 2
test foreach flatten added column inner join
test foreach u d f inner join
test foreach cast inner join
test foreach join required field
test foreach required field
tmp dir prop
fs name
job tracker
input
pig context
cluster
one time setup
set up
test set properties way num 0 1
test set properties way num 0 2
test set properties way num 0 3
test hadoop exception creation
test import list
tear down
one time tear down
get properties
get commands
register and store
check asserts
pc
migrate plan
test simple plan
test simple plan 2
test simple plan 3
test simple plan 4
test simple plan 5
test simple plan 6
test simple plan 7
test simple plan 8
print plan
print plan
print plan
script statement
temp script file
set up
test u d f without parameter
tear down
loop count
pig
null flags
cluster
set up
one time tear down
test group count with multiple fields
test simple count
test group count
test group reorder count
test group unique column count
test group duplicate column count
generate input
cur hdfs dir
cur hdfs root
set up before class
tear down after class
set up
tear down
test get absolute path
test get absolute path 2
test get absolute path 3
test get absolute path 4
test comma separated string
test comma separated string 2
test comma separated string 4
test comma separated string 5
test comma separated string 6
test comma separated string 7
test comma separated string 8
test har url
script statement
temp script file
cluster
set up
one time tear down
test u d f return map local mode
test u d f return map map reduce mode
test u d f multi level output schema
tear down
log
loop count
cluster
pig
set up
one time tear down
test numeric eq
test numeric neq
test numeric gt
test bin cond
test nested bin cond
test numeric lt
test numeric gte
test numeric lte
pc
servers
cluster
set up
tear down
test get next tuple
one time tear down
test load remote rel
test load remote abs
test load remote rel scheme
test load remote abs scheme
test load remote abs auth
test load remote normalize
test glob chars
test comma separated string
test comma separated string 2
test comma separated string 3
test comma separated string 4
test comma separated string 5
test comma separated string 6
test non dfs location
test loading multiple files
check load path
check load path
test tuple schema
test bag schema
log
loop count
cluster
pig
null flags
set up
one time tear down
test add
test subtract
test multiply
test divide
generate input
r
lt
rt
op
set up
test operator
cluster
pig server
pig context
m tf
m bf
set up
one time tear down
test function inside function
test join
test driver method
test map lookup
test bag function with flattening
test sort with u d f
test distinct
test sort distinct
test nested plan
test nested plan with expression assignment
test limit
test complex data
test bin storage determine schema
test project bag
test bin storage determine schema 2
test cogroup with input from group
test utf 8 dump
test map u d f
test map u d f fail
test load ctor args
test nested plan for cloning
test arithmetic cloning
test expression re use
test identity
test cogroup after distinct
test algebraic distinct progress
test bin storage with large strings
cluster
one time tear down
test successive user funcs 1
test successive user funcs 2
test on cluster
set up
test local
run test
load with test load func
test no combiner use
test multi combiner use
test distinct aggs 1
test distinct no combiner
test for each no combiner
test jira pig 7 4 6
test jira pig 1 0 3 0
op
inp op
t
set up
tear down
test process input
pc
file base location
plan tester
set up
test simple 1
test by script 1
test by script 2
test by script 5
test by script 6
test s u m 1
test s u m 2
test generate 1
init string
cluster
pig server
tuple factory
bag factory
int input
int as long
long input
float input
float as double
double input
ba
ba as double
string input
byte array input
eval func map
input map
allowed input
expected map
stages
aggs
input type as string
set up
setup eval func map
one time tear down
test agg no combine
test agg single combine
test agg multiple combine
test agg empty bag with combiner
test agg empty bag
check zero or null
test a v g
test a v g intermediate
test a v g final
test c o u n t
test c o u n t intermed
test c o u n t final
test c o u n t s t a r
test c o u n t s t a r intermed
test c o u n t s t a r final
test s u m
test s u m intermed
test s u m final
test m i n
test m i n intermediate
test m i n final
test m a x
test m a x intermed
test m a x final
test math funcs
test string funcs
test stats func
check items g t
test misc func
test distinct
test distinct progress non algebraic
test c o n c a t
test multi c o n c a t
test s i z e
test l f pig
test l f text
test s f pig
test string u d fs
test t o k e n i z e
test d i f f
get input type
get expected
pc
test simple plan
test plan with cast
test join plan
test foreach plan
test foreach schema
test foreach plan 2
test co group
test co group 2
test co group 3
test co group 4
get all uids
migrate plan
cluster
empty dir
i n p f i l e 2 n u m s
i n p f i l e 2 n u m 1 c h a r 1 b a g
inp file empty
set up
tear down
one time setup
one time tear down
test union on schema same schema
test union on schema filter
test union on schema succ ops
test union on schema cast on byte array
test union on schema scoped column name
test union on schema scoped column name both inp 1
test union on schema scoped column name both inp 2
test union on schema scoped column name neg
test union on schema diff num type
test union on schema no common cols
test union on schema additional column
test union on schema 3 inputs
test union on schema byte array conversions
test union on schema no schema
test union on schema null alias in field schema
check schema ex
test union on schema incompatible types
test union on schema input udfs
test union on schema udf type evolution
test union on schema udf type evolution 2
test union on schema scope multi
test two unions
m dfs
m mr
m file sys
m conf
instance
is setup
mini cluster
setup mini dfs and mr clusters
build cluster
shut down
finalize
shutdown mini dfs and mr clusters
get properties
set property
get file system
error if not setup
i n p u t f i l e 1
i n p u t f i l e 2
i n p u t f i l e 3
i n p u t f i l e 4
i n p u t f i l e 5
i n p u t f i l e 6
i n p u t f i l e 7
pig server
cluster
test skewed join
set up
one time tear down
create files
tear down
test skewed join with group
test skewed join with no properties
test skewed join reducers
test skewed join 3 way
test skewed join map key
test skewed join key partition
test skewed join null keys
test skewed join outer
test skewed join one value
test skewed join many reducers
test skewed join empty input
test recursive file listing
test skewed join u d f
input file
pig server
cluster
test collected group
set up
create files
tear down
test non collectable loader
test collected grp specified in single quotes 1
test collected grp specified in single quotes 2
one time tear down
test p o mapside group no null plans
test mapside group parser no support for multiple inputs
test mapside group parser no support for group all
test mapside group parser no support for by expression
test mapside group by one column
test mapside group by multiple columns
test mapside group by star
set up
tear down
test integer ne
test integer eq
test integer and null values
test long ne
test long eq
test long and null values
test float ne
test float eq
test float and null values
test double ne
test double eq
test double and null values
test string ne
test string eq
test string and null values
test data byte array ne
test data byte array eq
test tuple eq
test tuple ne
test map eq
test map ne
test data byte array and null values
check null values
i n p u t f i l e 1
pig server
cluster
test poisson sample loader
set up
one time tear down
create files
tear down
test num samples
test instantiation
pc
plan tester
tear down
test error empty input
test error non foreach input
test foreach no flatten
test foreach no successors
test foreach streaming
test foreach distinct
test foreach foreach
test foreach filter
test foreach split output
test foreach limit
test foreach union
test foreach cogroup
test foreach group by
test foreach sort
test foreach sort negative 1
test foreach sort negative 2
test foreach flatten added column sort
test foreach u d f sort
test foreach cast sort
test foreach cross
test foreach cross 1
test foreach cross 2
test foreach flatten added column cross
test foreach u d f cross
test foreach cast cross
test foreach f r join
test foreach f r join 1
test foreach f r join 2
test foreach flatten added column f r join
test foreach u d f f r join
test foreach cast f r join
test foreach inner join
test foreach inner join 1
test foreach inner join 2
test foreach flatten added column inner join
test foreach u d f inner join
test foreach cast inner join
test foreach join required field
test foreach required field
test foreach with user defined schema
test foreach with user defined schema 2
migrate and optimize plan
migrate plan
m bag factory
m tuple factory
load flat tuple
load tuple
load tuple
load nest tuple
load nest tuple
load nest tuple
add to tuple
build tuple
build bin tuple
create tuple
create bag
create bag of one column
create map
to data byte arrays
load nest tuple
load tuple
create input file
create local input file
write to file
create input file
create input file
create input file
create temp file del on exit
delete file
delete file
exists
check query outputs
check query outputs after sort
check str contains sub str
copy from local to cluster
copy from cluster to local
print query output
encode escape
generate u r i
get schema from string
get schema from string
get pig constant
get tuples from constant tuple strings
create file
build physical plan
migrate to new l p
optimize new l p
build physical plan from new l p
get new optimized physical plan
build m r plan
build m r plan with optimizer
register multi line query
execute java command
execute java command and return info
get contents
delete directory
create input file
print plan
print plan
print plan
read file 2 tuple list
reset log
check log file message
pig server
cluster
input file
input file 2
loop size
test best fit cast
set up
tear down
one time tear down
test byte array cast 1
test byte array cast 2
test byte array cast 3
test byte array cast 4
test byte array cast 5
test byte array cast 6
test byte array cast 7
test byte array cast 8
test byte array cast 9
test byte array cast 1 0
test byte array cast 1 1
test byte array cast 1 2
test byte array cast 1 3
test byte array cast 1 4
test byte array cast 1 5
test byte array cast 1 6
test int sum
test long sum
test float sum
test double sum
test 1
test 2
test 3
test 4
test 5
test 6
null flags
cluster
pig
tmp file
test algebraic instantiation
set up
test algebraic instantiation
test regular instantiation
cluster
i n p u t 1
i n p u t 2
set up before class
tear down after class
test arithmetic operators
compare
cluster
my pig
dummy store with outputformat class
set up before class
tear down after class
set up
tear down
test multi query with two stores 2
test multi query with two loads 2
test multi query phase 3 base case 2
test multi query phase 3 without combiner 2
test multi query phase 3 with mixed combiner 2
test multi query phase 3 with different map data types 2
test multi query phase 3 with different map data types 3
test multi query phase 3 streaming in reducer 2
test multi query with pig mix l 1 2 2
test multi query with co group 2
test multi query with f j 2
test multi query with intermediate stores 2
test multi query with split in map and multi merge
test multi query with two stores 2 execs
test multi query with three stores 2
test multi store with output format
delete output files
cluster
pig server
t e s t f i l t e r c o u n t 3 i n p u t
set up
tear down
one time tear down
test filter count 1
test filter count 2
test filter count 3
test filter 1
test filter 2
plan
pc
migrate plan
test 1
test 2
test 3
test 4
test 5
combo runner 2
test 6
combo runner 3
test 7
conf
pig input format
ok
set up
test 1
test 2
test 3
test 4
test 5
test 6
test 7
test 8
test 9
check locations
check location ordering
log
loop count
cluster
pig
set up
one time tear down
test string eq
test string neq
test string gt
test string gte
test string lt
test string lte
sb
op limit optimizer printer
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
append op
append edges
print to string
log
cluster
pig
set up
one time tear down
test big group all
test big group all with null
test b zip 2 aligned
big group all
test store function
test store function no nulls
test store function with nulls
store function
test qualified functions
test qualified functions with nulls
test defined functions
test defined functions no nulls
test defined functions with nulls
defined functions
test pig server
gen data set file 1
file
cluster
max
r
multi input created
count
one time tear down
test map only
test map only bin storage
test map reduce only
test map reduce only bin storage
test map combine reduce
test map combine reduce bin storage
test multiple m r jobs
test map only multi query stores
test multi query stores
test join input counters
test cogroup input counters
test skewed input counters
test self join input counters
test input counters
test 1
test 2
test 3
test 4
assert aliases
assert types
parse schema
cluster
pig server
set up
one time tear down
test arith expressions
test bin cond
test foreach generate
test outer join
test concat and size
test explicit cast
test complex null constants
test map null key failure
input file
one time setup
one time tear down
set up
tear down
test foreach star schema unkown
pc
plan tester
test simple
test multiple filter
test multiple filter 2
test multiple filter not possible
test not possible filter
test simple 2
test 1
test 2
test 3
test 4
test filter foreach
test filter foreach added field
test filter foreach cast
test filter cast foreach
test filter constant condition foreach
test filter u d f foreach
test filter foreach flatten
test push up filter with scalar
migrate and optimize plan
migrate plan
cluster
one time tear down
test local mode input positive
test local mode negative 2
test map reduce mode input positive
test map reduce mode input negative 2
test pig server store
test pig server store neg
test validation neg
gen new load store plan
gen new operator key id
generate temp file
generate non existence temp file
create hadoop temp file
create hadoop non existence temp file
set up
tear down
run test
pick test
test operator
log
cluster
setup
shutdown
test block boundary
test prune columns with missing fields
bag
r
tf
mini cluster
max
one time tear down
test p o neg int
test p o neg int and null
test p o neg long
test p o neg long and null
test p o neg double
test p o neg double and null
test p o neg float
test p o neg float and null
test p o neg type
file base location
max size
pc
plan tester
print limit graph
optimize plan
optimize plan
compare with golden file
test type cast insertion
test o p limit 1 optimizer
test o p limit 2 optimizer
test o p limit 3 optimizer
test o p limit 4 optimizer
test o p limit 5 optimizer
test o p limit 6 optimizer
test o p limit 7 optimizer
test o p limit 8 optimizer
test o p limit 9 optimizer
test o p limit 1 0 optimizer
test op limit optimizer check
test err implicit split inserter
test err type cast inserter
test err op limit optimizer
test o p limit 1 1 optimizer
test o p limit 1 2 optimizer
test load get schema called once
log
dat file
default block size
total
in circle
cluster
total length
total length test
pig
file name
tmp file 1
set up
tear down
one time tear down
test pi
pc
ld file
exp file
php
st file
hadoop ld file
grp name
r
cur dir
inp dir
gol dir
cluster
set up
tear down
one time tear down
test job control compiler err
test default parallel
test default parallel in sort
test default parallel in skew join
test reducer num estimation
test reducer num estimation for order by
submit
cluster
pig server
m tf
m bf
set up
one time tear down
test python standard script
test python script with schema function
test python script u d f no decorator
test python script u d f bag input
test python script u d f map input
test python script u d f null input output
test python absolute path
test
cluster
pig script
set up once
test nto n
test implicit nto n
test text input
test subset
test override
test inline pig script
test file output
test arg files
test get last alias
test with udf
test store
test with mock
parser
override
set up
test remove stores
test remove dumps
test replace load
test get store alias
exec
output schema
u d f context test eval func 2
exec
vals
u d f context test loader
get next
gen rand map
gen rand string
gen rand large string
gen rand d b a
gen rand text d b a
get small tuple field schema
gen rand small tuple
gen rand small tuple
gen rand small tup data bag with nulls
get small tup data bag field schema
gen rand small tup data bag
gen rand small bag tuple
get small bag text tuple field schema
gen rand small bag text tuple
gen rand full tup data bag
get full tup text data bag field schema
gen rand full tup text data bag
gen rand small bag tuple with nulls
gen rand small bag text tuple with nulls
gen float data bag
get float data bag field schema
gen mixed tuple to convert
get mixed tuple to convert field schema
count
accumulator bag count
accumulate
get value
cleanup
exec
map
exec
sb
accumulative sum bag
accumulate
get value
cleanup
exec
file
cur mark
local seekable input stream
seek
tell
read
read
read
available
skip
close
mark
reset
mark supported
stop words file
main
bag count
exec
disp after num tuples
bag contains
compare bags
compare cogroup outputs
project bag
project bag
compare input streams
compare byte array
are files same
trim tuple
create temp file
map equals
tuple equals
bag equals
exec
exec
output schema
serial version u i d
p o cast dummy
p o cast dummy
visit
name
supports multiple inputs
get next
get next
get child expressions
u d f context test eval func
exec
count
exec
gen dummy l o load
gen flat schema
gen new operator key
print type graph
print message collector
print current method name
get current method name
exec
output schema
scope
aliases
logical op table
alias op
file name map
pig context
logical plan tester
logical plan tester
reset
build plan
build plan throw exception on error
type check plan
optimize plan
type check against dot file
type check against dot file
type check using dot file
type check using dot file
print plan
build plan
parse
build plan throw exception on error
set plan
set projection map
rebuild projection map
rebuild schema
get partition
filter file name
lookup table
filterfromfile
filterfromfile
init
exec
exec
output schema
r
gte
gt
lte
lt
pc
expr const
comp greater than expr
comp greater than expr
comp and expr
expr project
expr project
comp g t or equal to expr
comp equal to expr
comp equal to expr
comp not equal to expr
comp is null expr
comp less than expr
comp l t or equal to expr
top local rearrange op
top global rearrange op
top package op
top for each op
top union op
top generate op with ex plan
top generate op with ex plan l r
top generate op with ex plan for fe
top generate op with ex plan for fe flat
top generate op with ex plan for fe
top generate op with ex plan for fe
top local rearrange o p with plan
top local rearrange o p with plan plain
top for each o p with plan
top for each o p with plan
top for each o p with plan
top for each o p with plan
top load op
top filter op
connected filter op
top limit op
top filter op with ex plan
top filter op with proj
top filter op with proj
top filter op with proj with cast
top read op
dummy pig storage op
top store op
set r
m r op
get temp file spec
top split op
grp chain
loaded grp chain
loaded filter
top for each o p with u d f
arith plan
get o k
set pc
load
load from file
dot graph visitor
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
visit
match
diff keys
append op key
match
get sorted key list
name
edges
nodes
attributes
dot graph
create operator
create l o load
create l o filter
create l o distinct
create l o sort
create l o for each
create l o split
create l o split output
create l o cogroup
create l o union
create l o cross
fill schema
replace alias by null
load
load from file
load from file with graph
create operator
construct plan
get key
name
attributes
from node
to node
debug stream
jjbit vec 0
jjnext states
jjstr literal images
lex state names
jjnew lex state
jjto token
jjto skip
jjto special
jjto more
input stream
jjrounds
jjstate set
jjimage
image
jjimage len
length of match
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj start nfa with states 0
jj move nfa 0
jj move string literal dfa 0 2
jj move nfa 2
jj stop string literal dfa 1
jj start nfa 1
jj move string literal dfa 0 1
jj move string literal dfa 1 1
jj move nfa 1
d o t parser token manager
d o t parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
skip lexical actions
jj check n add
jj add states
jj check n add two states
nodes
marks
sp
mk
node created
j j t d o t parser state
node created
reset
root node
push node
pop node
peek node
node arity
clear node scope
open node scope
close node scope
close node scope
serial version u i d
lexical error
static lexer error
invalid lexical state
loop detected
error code
add escapes
lexical error
get message
token mgr error
token mgr error
token mgr error
static flag
bufsize
available
token begin
bufpos
bufline
bufcolumn
column
line
prev char is c r
prev char is l f
input stream
buffer
max next char ind
in buf
tab size
set tab size
get tab size
expand buff
fill buff
begin token
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
simple char stream
simple char stream
simple char stream
re init
re init
re init
simple char stream
simple char stream
simple char stream
simple char stream
simple char stream
simple char stream
re init
re init
re init
re init
re init
re init
get image
get suffix
done
adjust begin line column
serial version u i d
current token
expected token sequences
token image
eol
parse exception
parse exception
parse exception
initialise
add escapes
serial version u i d
kind
begin line
begin column
end line
end column
image
next
special token
get value
token
token
token
to string
new token
new token
parent
children
id
value
parser
simple node
simple node
jjt open
jjt close
jjt set parent
jjt get parent
jjt add child
jjt get child
jjt get num children
jjt set value
jjt get value
to string
to string
dump
jjtree
token source
jj input stream
token
jj nt
jj ntk
jj scanpos
jj lastpos
jj la
jj gen
jj la 1
jj la 1 0
jj 2 rtns
jj rescan
jj gc
jj ls
jj expentries
jj expentry
jj kind
jj lasttokens
jj endpos
unquote
parse
attribute statement
node statement
edge statement
attribute list
attribute
jj 2 1
jj 3 r 5
jj 3 r 4
jj 3 1
jj la 1 init 0
d o t parser
d o t parser
re init
re init
d o t parser
re init
d o t parser
re init
jj consume token
jj scan token
get next token
get token
jj ntk
jj add error token
generate parse exception
enable tracing
disable tracing
jj rescan token
jj save
plan 1 to plan 2
plan 2 to plan 1
node matcher
structurally equals
structurally equals
set node matcher
generate inverse map
diff outgoing edges
append op key
append missing edge message
structurally equals
find mismatch schema
find mismatch node type
get tuples
test data atom evals
test data bag evals
test filters
main
exec
output schema
get arg to func mapping
exec
output schema
get arg to func mapping
 ngram size limit
exec
output schema
get arg to func mapping
 url pattern
exec
get arg to func mapping
compute mean
compute s d
exec
output schema
split to words
make n gram
unique bytes
min step size
data
key distribution
add
add
set min step size
length
size
get min step size
get keys
get block distribution
merge
resize
swap
log
conf compress
default compress
conf min block size
default min block size
conf min split size
default min split size
split slop
conf non datafile prefix
special file prefix
schema file
meta file
key range for default sorted split
block name index
make meta file path
get compression
get min block size
get non data file prefix
get min split size
drop
build index
dump info
dump info
dump info
head to string
main
unique bytes
data distri
block distribution
add
reduce data distri
add
add
add
sum
get length
get hosts
indent
meta file
create writer
create reader
size
rows
begin key
end key
get begin key
get end key
get size
get rows
read fields
write
column delimiter
schema version
m fields
m names
projection
schema
schema
schema
schema
schema
schema
add
get column
get columns
get column
get column name
get typed columns
get column index
get num columns
parse
to string
stringify schema
normalize
compare to
equals
read fields
write
init
init
init
get projection schema
get column schema
get column schema on parsed name
get column schema
union schema
to projection string
compare utils
meta block does not exist
log
t file dumper
dump info
buf
count
simple buffered output stream
flush buffer
write
write
flush
size
in
pos
end
mark
one byte
bounded range file input stream
available
read
read
read
skip
mark
reset
mark supported
close
meta block already exists
chunk
buffer
offset
len
byte array
byte array
byte array
buffer
offset
size
log
chunk buf size attr
fs input buf size attr
fs output buf size attr
max key size
api version
compression gz
compression lzo
compression none
comparator memcmp
comparator jclass
get chunk buffer size
get f s input buffer size
get f s output buffer size
make comparator
t file
get supported compression algorithms
main
buffer
limit
count
bounded byte array output stream
bounded byte array output stream
write
write
reset
reset
get limit
get buffer
size
api version
log
b c file
utils
write v int
write v long
read v int
read v long
write string
read string
lower bound
upper bound
lower bound
upper bound
log
compression
get compression algorithm by name
get supported algorithms
version
sorted
comparator
schema
name
compressor
serializer
group
owner
perm
schema file
schema version
to string
make file path
load
c g schema
c g schema
c g schema
equals
exists
drop
is sorted
get comparator
get name
set name
get serializer
get compressor
get group
get perm
get owner
create
read
get schema
sb
is first
log
instance
to c s v string
to c s v buffer
print comma unless first
csv zebra tuple output
reset
create csv zebra tuple output
to string
write byte
write bool
write int
write long
write float
write double
write string
write buffer
write null
start tuple
end tuple
write tuple
start bag
write bag
end bag
start map
end map
write map
m c gs
m c g list
m execs
m stitch size
m split size
m schema
m c g schemas
m partition info
m projection
m p c need tmp tuple
m p c need map
comparator
m sorted
m sort info
partition
partition
partition
store const
get sort info
is sorted
get comparator
get schema
get partition info
get c g schemas
get c g schema
get col mapping
build stitch
handle map stitch
get c g entry
build split
handle map split
read
insert
set source
get projection
get projection
get split map
generate default c g schema
set split
set c g index
get c g index
get c g name
is c g needed
source table vcolumn name
m projection
m num columns
m proj str
m schema
m keys
projection
is virtual column
get virtual column indices
projection
get keys
get schema
get projection schema
get column schema
to string
get num columns
get num columns
get projection str
to schema
get column index
default comparator
global
columns
indices
types
comparator
schema
sorted column delimiter
sort info
get sort column names
get sort column types
get sort indices
size
get comparator
equals
parse
to sort string
tf
create tuple
create tuple
create bag
create bag
reset tuple
check type error
check column type
check column
check map column
check collection column
check record column
check compatible
check number column compatible
format tuple
mapreduce output path
mapreduce multi output path
mapreduce output schema
mapreduce output storagehint
mapreduce output sortcolumns
mapreduce output comparator
is multi
zebra output partitioner class
zebra output partitioner class arguments
mapreduce output checktype
mapred output path
mapred multi output path
mapred output schema
mapred output storagehint
mapred output sortcolumns
mapred output comparator
get output path
set output path
get multi output path
set multi output path
get output schema
set output schema
get output storage hint
set output storage hint
get output sort columns
set output sort columns
get output comparator
set output comparator
get is multi
set is multi
get check type
set check type
get zebra output partitioner class
set zebra output partitioner class
get output partition class arguments
set output partition class arguments
log
serial version u i d
zebra tuple
zebra tuple
zebra tuple
zebra tuple
to string
self
new tuple
new tuple
new tuple
new tuple no copy
new tuple
tuple class
zebra tuple factory
get zebra tuple factory instance
token source
jj input stream
token
jj nt
jj ntk
jj scanpos
jj lastpos
jj la
jj gen
jj la 1
jj la 1 0
jj 2 rtns
jj rescan
jj gc
jj ls
jj expentries
jj expentry
jj kind
jj lasttokens
jj endpos
main
type
composite type
basic type
column schema
projection column schema
atom schema
schema map
schema record
schema collection
schema collection entry
anonymous column schema
anonymous atom schema
anonymous schema map
anonymous schema record
anonymous schema collection
record schema internal
record schema
projection schema
map schema
jj 2 1
jj 2 2
jj 2 3
jj 2 4
jj 2 5
jj 2 6
jj 3 r 6
jj 3 3
jj 3 2
jj 3 6
jj 3 5
jj 3 r 4
jj 3 1
jj 3 4
jj 3 r 5
jj la 1 init 0
table schema parser
table schema parser
re init
re init
table schema parser
re init
table schema parser
re init
jj consume token
jj scan token
get next token
get token
jj ntk
jj add error token
generate parse exception
enable tracing
disable tracing
jj rescan token
jj save
serial version u i d
kind
begin line
begin column
end line
end column
image
next
special token
get value
token
token
token
to string
new token
new token
debug stream
jjbit vec 0
jjnext states
jjstr literal images
lex state names
jjto token
jjto skip
input stream
jjrounds
jjstate set
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj move string literal dfa 7 0
jj move string literal dfa 8 0
jj move string literal dfa 9 0
jj move string literal dfa 1 0 0
jj move string literal dfa 1 1 0
jj start nfa with states 0
jj move nfa 0
table storage parser token manager
table storage parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
jj check n add
jj add states
jj check n add two states
jj check n add states
serial version u i d
current token
expected token sequences
token image
eol
parse exception
parse exception
parse exception
initialise
add escapes
static flag
bufsize
available
token begin
bufpos
bufline
bufcolumn
column
line
prev char is c r
prev char is l f
input stream
buffer
max next char ind
in buf
tab size
set tab size
get tab size
expand buff
fill buff
begin token
update line column
read char
get column
get line
get end column
get end line
get begin column
get begin line
backup
simple char stream
simple char stream
simple char stream
re init
re init
re init
simple char stream
simple char stream
simple char stream
simple char stream
simple char stream
simple char stream
re init
re init
re init
re init
re init
re init
get image
get suffix
done
adjust begin line column
m schema
m default c g index
m name
m compressor
m serializer
m owner
m group
m perm
m c g count
partition
comparator
token source
jj input stream
token
jj nt
jj ntk
jj scanpos
jj lastpos
jj la
jj gen
jj la 1
jj la 1 0
jj la 1 1
jj 2 rtns
jj rescan
jj gc
jj ls
jj expentries
jj expentry
jj kind
jj lasttokens
jj endpos
table storage parser
storage schema
ascdsc
field schema
column schema
atom schema
schema map
schema record
anonymous column schema
anonymous schema record
anonymous schema map
record schema
anonymous record schema
anonymous map schema
hash keys
hash key
jj 2 1
jj 2 2
jj 2 3
jj 2 4
jj 2 5
jj 2 6
jj 2 7
jj 3 r 8
jj 3 6
jj 3 r 6
jj 3 r 1 1
jj 3 3
jj 3 r 1 2
jj 3 2
jj 3 1
jj 3 r 1 0
jj 3 r 7
jj 3 r 1 5
jj 3 r 9
jj 3 5
jj 3 4
jj 3 r 1 6
jj 3 r 1 3
jj 3 r 1 4
jj 3 7
jj la 1 init 0
jj la 1 init 1
table storage parser
table storage parser
re init
re init
table storage parser
re init
table storage parser
re init
jj consume token
jj scan token
get next token
get token
jj ntk
jj add error token
generate parse exception
enable tracing
disable tracing
jj rescan token
jj save
serial version u i d
lexical error
static lexer error
invalid lexical state
loop detected
error code
add escapes
lexical error
get message
token mgr error
token mgr error
token mgr error
debug stream
jjbit vec 0
jjnext states
jjstr literal images
lex state names
jjto token
jjto skip
input stream
jjrounds
jjstate set
cur char
cur lex state
default lex state
jjnew state cnt
jjround
jjmatched pos
jjmatched kind
set debug stream
jj stop string literal dfa 0
jj start nfa 0
jj stop at pos
jj move string literal dfa 0 0
jj move string literal dfa 1 0
jj move string literal dfa 2 0
jj move string literal dfa 3 0
jj move string literal dfa 4 0
jj move string literal dfa 5 0
jj move string literal dfa 6 0
jj move string literal dfa 7 0
jj move string literal dfa 8 0
jj move string literal dfa 9 0
jj start nfa with states 0
jj move nfa 0
table schema parser token manager
table schema parser token manager
re init
re init rounds
re init
switch to
jj fill token
get next token
jj check n add
jj add states
jj check n add two states
jj check n add states
